{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5501,
     "status": "ok",
     "timestamp": 1743258567362,
     "user": {
      "displayName": "Caleb Ong",
      "userId": "09148710192798478088"
     },
     "user_tz": -480
    },
    "id": "tGi5T15Be_zA",
    "outputId": "2e4b7200-2972-444e-9a72-36872a2493aa"
   },
   "outputs": [],
   "source": [
    "# Block 1: Import Libraries\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from wordcloud import WordCloud\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "# Add gensim imports for coherence calculation\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.coherencemodel import CoherenceModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1743258567363,
     "user": {
      "displayName": "Caleb Ong",
      "userId": "09148710192798478088"
     },
     "user_tz": -480
    },
    "id": "XNt7ThAOfA-S",
    "outputId": "182ce649-05d9-4c40-a0a7-b1082ec6ded4"
   },
   "outputs": [],
   "source": [
    "# Block 2: Define Paths for Data and Output\n",
    "project_root = '../../'\n",
    "processed_dir = os.path.join(project_root, 'Data', 'Historical Reddit', 'LDA_NMF_Data')\n",
    "base_output_dir = os.path.join(project_root, 'outputs', 'topic_modeling', 'lda')\n",
    "model_output_dir = os.path.join(base_output_dir, 'models')\n",
    "evaluation_output_dir = os.path.join(base_output_dir, 'evaluations')\n",
    "viz_output_dir = os.path.join(base_output_dir, 'visualizations', 'wordclouds')\n",
    "# doc_topics_output_dir = os.path.join(base_output_dir, 'document_topics')\n",
    "\n",
    "os.makedirs(model_output_dir, exist_ok=True)\n",
    "os.makedirs(evaluation_output_dir, exist_ok=True)\n",
    "os.makedirs(viz_output_dir, exist_ok=True)\n",
    "# os.makedirs(doc_topics_output_dir, exist_ok=True)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19168,
     "status": "ok",
     "timestamp": 1743258586539,
     "user": {
      "displayName": "Caleb Ong",
      "userId": "09148710192798478088"
     },
     "user_tz": -480
    },
    "id": "vNg8w8g8fCsR",
    "outputId": "9b876084-edf5-46de-fb05-33ba5ab9b3c3"
   },
   "outputs": [],
   "source": [
    "# Block 3: Load and Merge Data from JSON Files\n",
    "dfs = []\n",
    "for fname in os.listdir(processed_dir):\n",
    "    if fname.startswith('lda_nmf_r_') and fname.endswith('.json'):\n",
    "        file_path = os.path.join(processed_dir, fname)\n",
    "        subreddit_name = fname.replace('lda_nmf_r_', '').replace('.json', '')\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data_json = json.load(f)\n",
    "        df = pd.DataFrame(data_json)\n",
    "        df['subreddit'] = subreddit_name\n",
    "        dfs.append(df)\n",
    "all_posts = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "print(f\"Total number of posts: {len(all_posts)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8242,
     "status": "ok",
     "timestamp": 1743258594783,
     "user": {
      "displayName": "Caleb Ong",
      "userId": "09148710192798478088"
     },
     "user_tz": -480
    },
    "id": "ZgwjY5SHfGz5",
    "outputId": "0f19ae7f-e274-4fed-d189-362670ddbdb5"
   },
   "outputs": [],
   "source": [
    "# Block 4: Data Preparation for Topic Modeling\n",
    "all_posts['text_for_topic'] = all_posts['processed_tokens_lda_nmf'].apply(lambda tokens: ' '.join(tokens))\n",
    "texts = all_posts['processed_tokens_lda_nmf'].tolist() # Needed for Gensim coherence\n",
    "\n",
    "# Create document-term matrix using Count Vectorizer for scikit-learn LDA\n",
    "print(\"Creating document-term matrix for scikit-learn LDA...\")\n",
    "vectorizer = CountVectorizer(\n",
    "    max_df=0.95,\n",
    "    min_df=5,\n",
    "    max_features=5000,\n",
    "    ngram_range=(1, 2)\n",
    ")\n",
    "dtm = vectorizer.fit_transform(all_posts['text_for_topic'])\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(f\"Document-term matrix shape: {dtm.shape}\")\n",
    "\n",
    "# Create Gensim dictionary and corpus (required for coherence calculation later)\n",
    "print(\"Creating Gensim dictionary and corpus for coherence evaluation...\")\n",
    "dictionary = Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "print(f\"Gensim dictionary size: {len(dictionary)}\")\n",
    "print(f\"Gensim corpus size: {len(corpus)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XkNGkeodfI80"
   },
   "outputs": [],
   "source": [
    "# Block 5: Hyperparameter Tuning for LDA Model using Grid Search and NPMI Coherence\n",
    "\n",
    "def get_topics_list(model, feature_names, n_top_words=15):\n",
    "    \"\"\"Extract top words for each topic from LDA model.\"\"\"\n",
    "    topics_list = []\n",
    "    for topic in model.components_:\n",
    "        top_words_idx = topic.argsort()[:-n_top_words - 1:-1]\n",
    "        top_words = [feature_names[i] for i in top_words_idx]\n",
    "        topics_list.append(top_words)\n",
    "    return topics_list\n",
    "\n",
    "search_params = {\n",
    "    'n_components': [10, 15, 20],\n",
    "    'learning_decay': [0.7, 0.9]\n",
    "}\n",
    "n_components_list = search_params['n_components']\n",
    "learning_decay_list = search_params['learning_decay']\n",
    "\n",
    "best_score = -np.inf\n",
    "best_params = {}\n",
    "coherence_scores = {}\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for n_components in n_components_list:\n",
    "    for learning_decay in learning_decay_list:\n",
    "        param_key = f\"k={n_components}, decay={learning_decay}\"\n",
    "        print(f\"  Testing {param_key}...\")\n",
    "        try:\n",
    "            lda_temp = LatentDirichletAllocation(\n",
    "                n_components=n_components,\n",
    "                learning_decay=learning_decay,\n",
    "                max_iter=20,\n",
    "                learning_method='online',\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            lda_temp.fit(dtm)\n",
    "\n",
    "            # Use feature_names from CountVectorizer (Block 4) for sklearn topics\n",
    "            topics = get_topics_list(lda_temp, feature_names)\n",
    "\n",
    "            # Use dictionary and texts (from Block 4) for Gensim coherence\n",
    "            coherence_model = CoherenceModel(\n",
    "                topics=topics,\n",
    "                texts=texts,\n",
    "                dictionary=dictionary,\n",
    "                coherence='c_npmi'\n",
    "                # corpus=corpus # Optional for c_npmi, but can be included\n",
    "            )\n",
    "            coherence_score = coherence_model.get_coherence()\n",
    "\n",
    "            coherence_scores[param_key] = coherence_score\n",
    "            print(f\"    NPMI Coherence: {coherence_score:.4f}\")\n",
    "\n",
    "            if coherence_score > best_score:\n",
    "                best_score = coherence_score\n",
    "                best_params = {'n_components': n_components, 'learning_decay': learning_decay}\n",
    "        except Exception as e:\n",
    "             print(f\"    Failed for {param_key}: {e}\")\n",
    "             coherence_scores[param_key] = np.nan\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"\\nTuning finished in {end_time - start_time:.2f} seconds.\")\n",
    "print(f\"All Coherence Scores: {coherence_scores}\")\n",
    "\n",
    "if not best_params:\n",
    "    print(\"Error: No best parameters found. LDA tuning failed.\")\n",
    "    best_lda_params = {'n_components': 10, 'learning_decay': 0.7} # Fallback parameters\n",
    "else:\n",
    "    print(f\"Best NPMI Score: {best_score:.4f}\")\n",
    "    print(f\"Best LDA Parameters found: {best_params}\")\n",
    "    best_lda_params = best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115
    },
    "executionInfo": {
     "elapsed": 446381,
     "status": "ok",
     "timestamp": 1743259041178,
     "user": {
      "displayName": "Caleb Ong",
      "userId": "09148710192798478088"
     },
     "user_tz": -480
    },
    "id": "IqdYn1vzfJyP",
    "outputId": "57112d35-99f7-4011-e093-0dd6e4b6bb0d"
   },
   "outputs": [],
   "source": [
    "# Block 6: Train Final LDA Model with Best Parameters\n",
    "\n",
    "# Using parameters found during tuning or fallback defaults\n",
    "print(\"Training final LDA model...\")\n",
    "final_lda = LatentDirichletAllocation(\n",
    "    n_components=best_lda_params['n_components'],\n",
    "    learning_decay=best_lda_params['learning_decay'],\n",
    "    max_iter=20,\n",
    "    learning_method='online',\n",
    "    random_state=42\n",
    ")\n",
    "final_lda.fit(dtm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 102,
     "status": "ok",
     "timestamp": 1743259248407,
     "user": {
      "displayName": "Caleb Ong",
      "userId": "09148710192798478088"
     },
     "user_tz": -480
    },
    "id": "rDrDMrOeQJ6x",
    "outputId": "7386cb40-6a1d-45fd-c115-b02c5c706888"
   },
   "outputs": [],
   "source": [
    "# Block 7: Save Trained LDA Model and Vectorizer\n",
    "print(\"Saving LDA model and vectorizer...\")\n",
    "with open(os.path.join(model_output_dir, 'lda_model.pkl'), 'wb') as f:\n",
    "    pickle.dump(final_lda, f)\n",
    "\n",
    "with open(os.path.join(model_output_dir, 'count_vectorizer.pkl'), 'wb') as f:\n",
    "    pickle.dump(vectorizer, f)\n",
    "print(f\"LDA model and CountVectorizer saved to {model_output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 135505,
     "status": "ok",
     "timestamp": 1743259422844,
     "user": {
      "displayName": "Caleb Ong",
      "userId": "09148710192798478088"
     },
     "user_tz": -480
    },
    "id": "P62p5XiFfLhG",
    "outputId": "e61a4eaf-6b93-4c0c-8f93-c4f9d9228e00"
   },
   "outputs": [],
   "source": [
    "# Block 8: Model Evaluation and Coherence Analysis\n",
    "\n",
    "def get_lda_topics(model, feature_names, n_top_words=15):\n",
    "    \"\"\"Extract top words for each topic from LDA model.\"\"\"\n",
    "    topics_list = []\n",
    "    for topic in model.components_:\n",
    "        top_words_idx = topic.argsort()[:-n_top_words - 1:-1]\n",
    "        top_words = [feature_names[i] for i in top_words_idx]\n",
    "        topics_list.append(top_words)\n",
    "    return topics_list\n",
    "\n",
    "lda_topics = get_lda_topics(final_lda, feature_names)\n",
    "\n",
    "coherence_model = CoherenceModel(\n",
    "    topics=lda_topics,\n",
    "    texts=texts,\n",
    "    corpus=corpus,\n",
    "    dictionary=dictionary,\n",
    "    coherence='c_npmi'\n",
    ")\n",
    "lda_coherence = coherence_model.get_coherence()\n",
    "\n",
    "# Calculate topic diversity (proportion of unique words across all topics)\n",
    "topic_diversity = len(set([word for topic in lda_topics for word in topic])) / (len(lda_topics) * 15)\n",
    "\n",
    "evaluation_results = {\n",
    "    'model_type': 'LDA',\n",
    "    'coherence_score': lda_coherence,\n",
    "    'n_topics': final_lda.n_components,\n",
    "    'topic_diversity': topic_diversity,\n",
    "    'parameters': {\n",
    "        'n_components': final_lda.n_components,\n",
    "        'learning_decay': final_lda.learning_decay,\n",
    "        'max_iter': final_lda.max_iter\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(os.path.join(evaluation_output_dir, 'lda_evaluation.json'), 'w') as f:\n",
    "    json.dump(evaluation_results, f, indent=4)\n",
    "\n",
    "print(\"\\nModel Evaluation Results:\")\n",
    "print(f\"NPMI Coherence Score: {lda_coherence:.4f}\")\n",
    "print(f\"Topic Diversity: {topic_diversity:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1743259425689,
     "user": {
      "displayName": "Caleb Ong",
      "userId": "09148710192798478088"
     },
     "user_tz": -480
    },
    "id": "HHDQ80vzfTCs",
    "outputId": "2917a783-4821-40dc-ec8f-278379c49433"
   },
   "outputs": [],
   "source": [
    "# Block 9: Function to Display Top Words for each Topic\n",
    "def display_topics(model, feature_names, n_top_words=15):\n",
    "    topics = {}\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        top_words_idx = topic.argsort()[:-n_top_words - 1:-1]\n",
    "        top_words = [feature_names[i] for i in top_words_idx]\n",
    "        topics[topic_idx] = top_words\n",
    "        print(f\"Topic {topic_idx+1}: {' '.join(top_words)}\") # Keep 1-based index for LDA display consistency\n",
    "    return topics\n",
    "\n",
    "print(\"\\nLDA Topics:\")\n",
    "lda_topics = display_topics(final_lda, feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9322,
     "status": "ok",
     "timestamp": 1743259437406,
     "user": {
      "displayName": "Caleb Ong",
      "userId": "09148710192798478088"
     },
     "user_tz": -480
    },
    "id": "Wnbi9tJqfTqe",
    "outputId": "80228f69-8a39-401d-c8a0-c23b90cd2a4b"
   },
   "outputs": [],
   "source": [
    "# Block 10: Create Word Clouds for Visualization\n",
    "def create_wordcloud(topics_dict, model_name):\n",
    "    \"\"\"Create and save word clouds for each topic.\"\"\"\n",
    "    for topic_idx, words in topics_dict.items():\n",
    "        word_freq = {word: 1 for word in words}\n",
    "        wordcloud = WordCloud(\n",
    "            width=800,\n",
    "            height=400,\n",
    "            background_color='white',\n",
    "            max_words=100\n",
    "        ).generate_from_frequencies(word_freq)\n",
    "\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.imshow(wordcloud, interpolation='bilinear')\n",
    "        plt.axis('off')\n",
    "        plt.title(f'{model_name} Topic {topic_idx+1}')\n",
    "\n",
    "        out_path = os.path.join(viz_output_dir, f'{model_name}_topic_{topic_idx+1}_wordcloud.png')\n",
    "        plt.savefig(out_path, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"Saved word cloud for {model_name} Topic {topic_idx+1}\")\n",
    "\n",
    "create_wordcloud(lda_topics, 'LDA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19170,
     "status": "ok",
     "timestamp": 1743259463923,
     "user": {
      "displayName": "Caleb Ong",
      "userId": "09148710192798478088"
     },
     "user_tz": -480
    },
    "id": "VmuW6NozfVfM",
    "outputId": "3f0f09af-1910-403b-80e4-81a509b77c13"
   },
   "outputs": [],
   "source": [
    "# Block 11: Assign Topics to Documents\n",
    "lda_doc_topic_dist = final_lda.transform(dtm)\n",
    "\n",
    "all_posts['lda_dominant_topic'] = np.argmax(lda_doc_topic_dist, axis=1)\n",
    "all_posts['lda_topic_confidence'] = np.max(lda_doc_topic_dist, axis=1)\n",
    "\n",
    "# Add one to make topics 1-indexed for better readability\n",
    "all_posts['lda_dominant_topic'] = all_posts['lda_dominant_topic'] + 1\n",
    "\n",
    "print(all_posts[['lda_dominant_topic', 'lda_topic_confidence']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 743,
     "status": "ok",
     "timestamp": 1743259529131,
     "user": {
      "displayName": "Caleb Ong",
      "userId": "09148710192798478088"
     },
     "user_tz": -480
    },
    "id": "N7Shu6OCcJGK",
    "outputId": "f90a05b2-81dc-4a28-bca5-3f023f4f1f4f"
   },
   "outputs": [],
   "source": [
    "# Block 12: Analyze Topic Distribution by Subreddit\n",
    "lda_topic_by_subreddit = pd.crosstab(\n",
    "    all_posts['subreddit'],\n",
    "    all_posts['lda_dominant_topic'],\n",
    "    normalize='index'\n",
    ") * 100\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(lda_topic_by_subreddit, annot=True, cmap='YlGnBu', fmt='.1f')\n",
    "plt.title('LDA Topic Distribution by Subreddit (%)')\n",
    "plt.xlabel('Topic')\n",
    "plt.ylabel('Subreddit')\n",
    "plt.savefig(os.path.join(evaluation_output_dir, 'lda_topic_by_subreddit.png'))\n",
    "plt.close()\n",
    "\n",
    "print(\"Topic distribution analysis by subreddit completed and saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 328,
     "status": "ok",
     "timestamp": 1743259535258,
     "user": {
      "displayName": "Caleb Ong",
      "userId": "09148710192798478088"
     },
     "user_tz": -480
    },
    "id": "e5kmRwpOKn3d",
    "outputId": "f2589695-85ad-462b-9b8b-b6e6ce4910c1"
   },
   "outputs": [],
   "source": [
    "# Block 13: Analyze Overall Topic Distribution\n",
    "# Note: Confidence values are model-specific and should NOT be used to compare between different models (e.g., LDA vs NMF).\n",
    "# These values are useful for: 1) filtering unreliable topic assignments, 2) identifying which topics have more\n",
    "# consistent assignments within this specific model, and 3) potentially flagging uncertain classifications in applications.\n",
    "\n",
    "topic_distribution = all_posts['lda_dominant_topic'].value_counts(normalize=True) * 100\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "topic_distribution.sort_index().plot(kind='bar')\n",
    "plt.title('Distribution of Topics Across All Posts')\n",
    "plt.xlabel('Topic Number')\n",
    "plt.ylabel('Percentage of Posts')\n",
    "plt.grid(True, axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(evaluation_output_dir, 'lda_topic_distribution.png'))\n",
    "plt.close()\n",
    "\n",
    "print(\"\\nTopic Distribution Statistics:\")\n",
    "print(topic_distribution.sort_index())\n",
    "\n",
    "# The following confidence analysis helps understand the relative strength of topic assignments WITHIN this model only.\n",
    "avg_confidence = all_posts['lda_topic_confidence'].mean()\n",
    "print(f\"\\nAverage LDA Topic Assignment Strength: {avg_confidence:.3f}\")\n",
    "\n",
    "topic_confidence = all_posts.groupby('lda_dominant_topic')['lda_topic_confidence'].mean()\n",
    "print(\"\\nTop 5 Topics with Highest Assignment Strength:\")\n",
    "print(topic_confidence.nlargest(5))\n",
    "print(\"\\nTop 5 Topics with Lowest Assignment Strength:\")\n",
    "print(topic_confidence.nsmallest(5))\n",
    "\n",
    "# When selecting between models (LDA, NMF, BERTopic, etc.), prioritize coherence scores, topic diversity,\n",
    "# and qualitative evaluation of topic interpretability rather than these confidence values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34972,
     "status": "ok",
     "timestamp": 1743259501521,
     "user": {
      "displayName": "Caleb Ong",
      "userId": "09148710192798478088"
     },
     "user_tz": -480
    },
    "id": "1mHbzt_mfXwj",
    "outputId": "6e6baa7c-aaf4-45c7-faac-081347af183d"
   },
   "outputs": [],
   "source": [
    "# Block 14: Process Each Subreddit Separately and Save Results (Commented Out)\n",
    "# for fname in os.listdir(processed_dir):\n",
    "#     if fname.startswith('processed_r_') and fname.endswith('.json'):\n",
    "#         file_path = os.path.join(processed_dir, fname)\n",
    "#         with open(file_path, 'r', encoding='utf-8') as f:\n",
    "#             df = pd.DataFrame(json.load(f))\n",
    "#\n",
    "#         if 'processed_tokens_ml' not in df.columns:\n",
    "#             continue\n",
    "#\n",
    "#         df['text_for_topic'] = df['processed_tokens_ml'].apply(lambda tokens: ' '.join(tokens))\n",
    "#         dtm_subreddit = vectorizer.transform(df['text_for_topic'])\n",
    "#         doc_topic_dist = final_lda.transform(dtm_subreddit)\n",
    "#\n",
    "#         df['lda_dominant_topic'] = np.argmax(doc_topic_dist, axis=1) + 1\n",
    "#         df['lda_topic_confidence'] = np.max(doc_topic_dist, axis=1)\n",
    "#\n",
    "#         out_file = fname.replace('.json', '_lda_topics.csv')\n",
    "#         out_path = os.path.join(doc_topics_output_dir, out_file)\n",
    "#         df[['id', 'title', 'lda_dominant_topic', 'lda_topic_confidence']].to_csv(out_path, index=False)\n",
    "#         print(\"Saved:\", out_file)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
