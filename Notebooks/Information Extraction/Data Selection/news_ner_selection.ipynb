{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from tqdm.notebook import tqdm # Use tqdm.notebook for better display in notebooks\n",
    "from collections import defaultdict\n",
    "import math # For ceiling division if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_length_category(text):\n",
    "    \"\"\"\n",
    "    Categorize text length into different ranges\n",
    "    Returns: 'short', 'medium', or 'long'\n",
    "    \"\"\"\n",
    "    word_count = len(text.split())\n",
    "    if word_count < 100:\n",
    "        return 'short'\n",
    "    elif word_count < 300:\n",
    "        return 'medium'\n",
    "    else:\n",
    "        return 'long'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_balanced_news(input_file, output_file, target_size=5000):\n",
    "    \"\"\"\n",
    "    Load news, filter non-truncated articles, and select a subset\n",
    "    balanced by text length (short, medium, long), aiming for target_size.\n",
    "    \"\"\"\n",
    "    print(f\"Loading news from {input_file}...\")\n",
    "    try:\n",
    "        with open(input_file, 'r', encoding='utf-8') as f:\n",
    "            news_data = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: Input file not found at {input_file}\")\n",
    "        return\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"ERROR: Could not decode JSON from {input_file}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Loaded {len(news_data)} total articles.\")\n",
    "\n",
    "    # --- Filtering ---\n",
    "    print(\"Filtering news articles (keeping non-truncated title/description)...\")\n",
    "    filtered_news = [\n",
    "        article for article in tqdm(news_data)\n",
    "        if isinstance(article, dict) # Basic check for valid article structure\n",
    "        and not article.get('truncated_title', True)\n",
    "        and not article.get('truncated_description', True)\n",
    "        and 'id' in article # Ensure articles have an ID\n",
    "        and 'processed_text_finbert' in article # Ensure text exists\n",
    "    ]\n",
    "    print(f\"\\nFound {len(filtered_news)} valid (non-truncated) articles with text and ID.\")\n",
    "\n",
    "    if not filtered_news:\n",
    "        print(\"ERROR: No valid articles found after filtering. Cannot proceed.\")\n",
    "        return\n",
    "\n",
    "    # --- Deduplication (just in case) ---\n",
    "    seen_ids = set()\n",
    "    unique_filtered_news = []\n",
    "    for article in filtered_news:\n",
    "        if article['id'] not in seen_ids:\n",
    "            unique_filtered_news.append(article)\n",
    "            seen_ids.add(article['id'])\n",
    "    if len(unique_filtered_news) < len(filtered_news):\n",
    "        print(f\"Removed {len(filtered_news) - len(unique_filtered_news)} duplicate articles based on ID.\")\n",
    "    filtered_news = unique_filtered_news\n",
    "\n",
    "\n",
    "    if len(filtered_news) < target_size:\n",
    "        print(f\"WARNING: Only {len(filtered_news)} valid articles available, which is less than the target size of {target_size}. Selecting all available.\")\n",
    "        target_size = len(filtered_news) # Adjust target size\n",
    "\n",
    "    # --- Categorize by Length ---\n",
    "    length_categories = defaultdict(list)\n",
    "    for article in filtered_news:\n",
    "        text = article.get('processed_text_finbert', '')\n",
    "        category = get_text_length_category(text)\n",
    "        length_categories[category].append(article)\n",
    "\n",
    "    print(\"\\nInitial Text length distribution of valid articles:\")\n",
    "    for category, articles in length_categories.items():\n",
    "        print(f\"- {category.capitalize()}: {len(articles)} articles\")\n",
    "\n",
    "    # --- Selection Phase 1: Balanced Selection ---\n",
    "    print(f\"\\n--- Selection Phase 1: Aiming for balance towards {target_size} articles ---\")\n",
    "    # Use math.ceil to slightly favor selecting more if target_size isn't divisible by 3\n",
    "    target_per_category = math.ceil(target_size / 3)\n",
    "    print(f\"Target per category (approx): {target_per_category}\")\n",
    "\n",
    "    selected_news = []\n",
    "    selected_ids = set()\n",
    "\n",
    "    for category in ['short', 'medium', 'long']: # Process in defined order\n",
    "        articles = length_categories.get(category, [])\n",
    "        available_for_category = [a for a in articles if a['id'] not in selected_ids] # Should be all initially\n",
    "        count_to_select = min(len(available_for_category), target_per_category)\n",
    "\n",
    "        if count_to_select > 0:\n",
    "                selected_from_category = random.sample(available_for_category, count_to_select)\n",
    "                selected_news.extend(selected_from_category)\n",
    "                selected_ids.update(a['id'] for a in selected_from_category)\n",
    "                print(f\"Selected {count_to_select} {category} articles.\")\n",
    "        else:\n",
    "                print(f\"No {category} articles available or needed in this phase.\")\n",
    "\n",
    "\n",
    "    # --- Selection Phase 2: Top Up if Needed ---\n",
    "    current_count = len(selected_news)\n",
    "    remaining_needed = target_size - current_count\n",
    "    print(f\"\\n--- Selection Phase 2: Currently selected {current_count} articles ---\")\n",
    "\n",
    "    if remaining_needed > 0:\n",
    "        print(f\"Need to select {remaining_needed} more articles.\")\n",
    "        # Get all *remaining* filtered articles that haven't been selected yet\n",
    "        all_filtered_ids = {a['id'] for a in filtered_news}\n",
    "        remaining_available_ids = all_filtered_ids - selected_ids\n",
    "        remaining_available_articles = [a for a in filtered_news if a['id'] in remaining_available_ids]\n",
    "\n",
    "        count_to_select_phase2 = min(len(remaining_available_articles), remaining_needed)\n",
    "\n",
    "        if count_to_select_phase2 > 0:\n",
    "            print(f\"Sampling {count_to_select_phase2} articles randomly from the remaining {len(remaining_available_articles)} available articles.\")\n",
    "            additional_selection = random.sample(remaining_available_articles, count_to_select_phase2)\n",
    "            selected_news.extend(additional_selection)\n",
    "            # selected_ids.update(a['id'] for a in additional_selection) # Update IDs if needed later\n",
    "            print(f\"Selected {count_to_select_phase2} additional articles.\")\n",
    "        else:\n",
    "            print(\"No more available articles to select in Phase 2.\")\n",
    "    else:\n",
    "        print(\"Target size reached or exceeded in Phase 1. No Phase 2 needed.\")\n",
    "\n",
    "\n",
    "    # --- Final Steps ---\n",
    "    print(\"\\n--- Finalizing Selection ---\")\n",
    "    # Shuffle the final list\n",
    "    random.shuffle(selected_news)\n",
    "\n",
    "    # Truncate if slightly over target (e.g., if target=5000, target_per_category=1667, 3*1667=5001)\n",
    "    if len(selected_news) > target_size:\n",
    "            print(f\"Selection slightly over target ({len(selected_news)}). Truncating to {target_size}.\")\n",
    "            selected_news = selected_news[:target_size]\n",
    "\n",
    "    print(f\"Final number of selected articles: {len(selected_news)}\")\n",
    "\n",
    "    # Simplify the selected news to only include id and text\n",
    "    simplified_news = [\n",
    "        {\n",
    "            \"id\": article[\"id\"],\n",
    "            \"text\": article[\"processed_text_finbert\"]\n",
    "        }\n",
    "        for article in selected_news\n",
    "    ]\n",
    "\n",
    "    # Final length distribution check\n",
    "    final_categories = defaultdict(int)\n",
    "    for article_simple in simplified_news:\n",
    "        category = get_text_length_category(article_simple[\"text\"])\n",
    "        final_categories[category] += 1\n",
    "\n",
    "    print(\"\\nFinal length distribution of selected articles:\")\n",
    "    for category, count in final_categories.items():\n",
    "        print(f\"- {category.capitalize()}: {count} articles\")\n",
    "\n",
    "    # Save selected news\n",
    "    os.makedirs(os.path.dirname(output_file), exist_ok=True) # Ensure output directory exists\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(simplified_news, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"\\nSaved {len(simplified_news)} selected articles to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "# !! Adjust this path to point to your actual FinBERT processed news file !!\n",
    "input_news_file = \"../../../Data/Historical News/FinBERT_Data/news.finbert.json\"\n",
    "\n",
    "# Output file relative to the notebook's location (e.g., inside Information Extraction/Data Selection/)\n",
    "# This will save it in Information Extraction/Unlabeled/\n",
    "output_news_file = \"../../../Data/Historical News/NER_Data/Unlabeled/5000_news_for_NER.json\"\n",
    "target_news_count = 5000\n",
    "\n",
    "# --- Run Selection ---\n",
    "select_balanced_news(input_news_file, output_news_file, target_news_count)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
