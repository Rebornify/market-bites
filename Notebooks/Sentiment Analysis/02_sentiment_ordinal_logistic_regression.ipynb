{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2917,
     "status": "ok",
     "timestamp": 1743078805909,
     "user": {
      "displayName": "Caleb Ong",
      "userId": "09148710192798478088"
     },
     "user_tz": -480
    },
    "id": "dz2Zs2IsD8U4",
    "outputId": "9a0988d0-da9f-4879-b80e-1e0f877bfd11"
   },
   "outputs": [],
   "source": [
    "# Block 1: Import Libraries\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import mord\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "mLpoC_ZYEVXj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root (Google Drive): ../../\n",
      "Looking for data in: ../../Data\\Historical Reddit\\ML_Data\n",
      "Using golden dataset from: ../../Data\\Historical Reddit\\golden_dataset_sentiment_non_batch.csv\n",
      "Saving outputs to: ../../outputs\\sentiment_analysis\\ordinal_logistic_regression\n"
     ]
    }
   ],
   "source": [
    "# Block 2: Define Paths for Data and Output\n",
    "\n",
    "# Define the root path of your project on Google Drive\n",
    "project_root = '../../'\n",
    "\n",
    "# Define the path to your processed data\n",
    "processed_dir = os.path.join(project_root, 'Data', 'Historical Reddit', 'ML_Data')\n",
    "\n",
    "# Define the path to the golden dataset\n",
    "golden_path = os.path.join(project_root, 'Data', 'Historical Reddit', 'golden_dataset_sentiment.csv')\n",
    "\n",
    "# Define the base output directory structure within the project root\n",
    "base_output_dir = os.path.join(project_root, 'outputs', 'sentiment_analysis', 'ordinal_logistic_regression')\n",
    "model_output_dir = os.path.join(base_output_dir, 'models')      # For saving the model and preprocessors\n",
    "results_output_dir = os.path.join(base_output_dir, 'results')   # For saving per-subreddit predictions\n",
    "# evaluation_output_dir = os.path.join(base_output_dir, 'evaluations') # Optional: If you save evaluations\n",
    "\n",
    "print(f\"Project root (Google Drive): {project_root}\")\n",
    "print(f\"Looking for data in: {processed_dir}\")\n",
    "print(f\"Using golden dataset from: {golden_path}\")\n",
    "print(f\"Saving outputs to: {base_output_dir}\") # Base output path for Ordinal Logistic Regression Sentiment\n",
    "\n",
    "# Create all necessary output directories if they don't exist\n",
    "os.makedirs(model_output_dir, exist_ok=True)\n",
    "os.makedirs(results_output_dir, exist_ok=True)\n",
    "# os.makedirs(evaluation_output_dir, exist_ok=True) # Uncomment if needed later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "qkpGuZt6EWj0"
   },
   "outputs": [],
   "source": [
    "# Block 3: Load and Merge Data from JSON Files and the Golden Dataset\n",
    "dfs = []\n",
    "for fname in os.listdir(processed_dir):\n",
    "    if fname.startswith('ml_r_') and fname.endswith('.json'):\n",
    "        file_path = os.path.join(processed_dir, fname)\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data_json = json.load(f)\n",
    "        df = pd.DataFrame(data_json)\n",
    "        dfs.append(df)\n",
    "all_posts = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Load the golden dataset that contains sentiment labels\n",
    "golden = pd.read_csv(golden_path)\n",
    "data = all_posts.merge(golden[['id', 'sentiment']], on='id', how='inner')\n",
    "\n",
    "# Add basic text statistics as features\n",
    "data['text_length'] = data['processed_tokens_ml'].apply(len)\n",
    "data['unique_words'] = data['processed_tokens_ml'].apply(lambda x: len(set(x)))\n",
    "data['avg_word_length'] = data['processed_tokens_ml'].apply(lambda x: np.mean([len(w) for w in x]) if x else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "J6y-vteCEXKF"
   },
   "outputs": [],
   "source": [
    "# Block 4: Preprocess Data for Machine Learning\n",
    "# Join tokens to form text for vectorization\n",
    "data['text'] = data['processed_tokens_ml'].apply(lambda toks: ' '.join(toks))\n",
    "X = data['text']\n",
    "y = data['sentiment']\n",
    "\n",
    "# Add numerical features\n",
    "X_num = data[['text_length', 'unique_words', 'avg_word_length']].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "eKKYNI-REXw4"
   },
   "outputs": [],
   "source": [
    "# Block 5: Split Data into Training, Validation, and Test Sets\n",
    "# First split: 80% train+val, 20% test\n",
    "X_trainval, X_test, X_num_trainval, X_num_test, y_trainval, y_test = train_test_split(\n",
    "    X, X_num, y, stratify=y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Second split: Split train+val into train and val\n",
    "X_train, X_val, X_num_train, X_num_val, y_train, y_val = train_test_split(\n",
    "    X_trainval, X_num_trainval, y_trainval, stratify=y_trainval, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "xtS1-R9MJVPl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tuning max_features and k (using ngram=(1,3), alpha=1.0) ---\n",
      "\n",
      "Trying max_features=10000, k=8000\n",
      "Validation F1-score: 0.4511\n",
      "Validation MSE: 0.8573\n",
      "New best parameters! max_features=10000, k=8000\n",
      "\n",
      "Trying max_features=10000, k=10000\n",
      "Validation F1-score: 0.4504\n",
      "Validation MSE: 0.8664\n",
      "\n",
      "Trying max_features=10000, k=10000\n",
      "Validation F1-score: 0.4504\n",
      "Validation MSE: 0.8664\n",
      "\n",
      "Trying max_features=15000, k=8000\n",
      "Validation F1-score: 0.4503\n",
      "Validation MSE: 0.8564\n",
      "New best parameters! max_features=15000, k=8000\n",
      "\n",
      "Trying max_features=15000, k=10000\n",
      "Validation F1-score: 0.4506\n",
      "Validation MSE: 0.8529\n",
      "New best parameters! max_features=15000, k=10000\n",
      "\n",
      "Trying max_features=15000, k=12000\n",
      "Validation F1-score: 0.4504\n",
      "Validation MSE: 0.8564\n",
      "\n",
      "Trying max_features=20000, k=8000\n",
      "Validation F1-score: 0.4515\n",
      "Validation MSE: 0.8551\n",
      "\n",
      "Trying max_features=20000, k=10000\n",
      "Validation F1-score: 0.4505\n",
      "Validation MSE: 0.8522\n",
      "New best parameters! max_features=20000, k=10000\n",
      "\n",
      "Trying max_features=20000, k=12000\n",
      "Validation F1-score: 0.4483\n",
      "Validation MSE: 0.8490\n",
      "New best parameters! max_features=20000, k=12000\n",
      "\n",
      "Best parameters based on MSE (fixed alpha, ngram):\n",
      "max_features: 20000\n",
      "k: 12000\n",
      "Best Validation F1-score (corresponding): 0.4483\n",
      "Best Validation MSE: 0.8490\n"
     ]
    }
   ],
   "source": [
    "# Block 6a: Tune max_features and k parameters together (Focus on MSE)\n",
    "# Define parameter grids for tuning\n",
    "max_features_values = [10000, 15000, 20000]\n",
    "k_values = [8000, 10000, 12000] # Adjust k based on max_features if needed\n",
    "\n",
    "# Initialize best parameters\n",
    "best_max_features = None\n",
    "best_k = None\n",
    "best_f1 = -1.0 # F1 is secondary\n",
    "best_mse = float('inf') # Primary metric is MSE\n",
    "\n",
    "print(\"--- Tuning max_features and k (using ngram=(1,2), alpha=1.0) ---\")\n",
    "\n",
    "# Tune max_features and k together\n",
    "for max_features in max_features_values:\n",
    "    for k in k_values:\n",
    "        # Ensure k is not greater than max_features\n",
    "        current_k = min(k, max_features)\n",
    "\n",
    "        print(f\"\\nTrying max_features={max_features}, k={current_k}\")\n",
    "\n",
    "        # Initialize vectorizer with current parameters\n",
    "        vectorizer = TfidfVectorizer(\n",
    "            max_features=max_features,\n",
    "            ngram_range=(1,2), # Keep ngram range fixed for now (based on previous best guess)\n",
    "            min_df=2,\n",
    "            max_df=0.95,\n",
    "            sublinear_tf=True\n",
    "        )\n",
    "\n",
    "        # Transform training data\n",
    "        X_train_vec = vectorizer.fit_transform(X_train)\n",
    "\n",
    "        # Feature selection\n",
    "        # Note: Need y_train which has original indices corresponding to X_train\n",
    "        selector = SelectKBest(chi2, k=current_k)\n",
    "        X_train_selected = selector.fit_transform(X_train_vec, y_train)\n",
    "\n",
    "        # Train a simple model for evaluation (using a fixed alpha for this stage)\n",
    "        model = mord.LogisticAT(alpha=1.0) # Use a default alpha, tune later\n",
    "        model.fit(X_train_selected, y_train)\n",
    "\n",
    "        # Evaluate on validation set\n",
    "        # Note: Need y_val which has original indices corresponding to X_val\n",
    "        X_val_vec = vectorizer.transform(X_val)\n",
    "        X_val_selected = selector.transform(X_val_vec)\n",
    "        y_val_pred = model.predict(X_val_selected)\n",
    "        f1 = f1_score(y_val, y_val_pred, average='weighted') # Calculate F1 for info\n",
    "        mse = mean_squared_error(y_val, y_val_pred)\n",
    "\n",
    "        print(f\"Validation F1-score: {f1:.4f}\")\n",
    "        print(f\"Validation MSE: {mse:.4f}\")\n",
    "\n",
    "        # --- Select based purely on best MSE ---\n",
    "        if mse < best_mse:\n",
    "            best_f1 = f1 # Update F1 for reporting if needed\n",
    "            best_mse = mse\n",
    "            best_max_features = max_features\n",
    "            best_k = current_k\n",
    "            print(f\"New best parameters! max_features={max_features}, k={current_k}\")\n",
    "\n",
    "print(f\"\\nBest parameters based on MSE (fixed alpha, ngram):\")\n",
    "print(f\"max_features: {best_max_features}\")\n",
    "print(f\"k: {best_k}\")\n",
    "print(f\"Best Validation F1-score (corresponding): {best_f1:.4f}\")\n",
    "print(f\"Best Validation MSE: {best_mse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "xC0ziJqyx_CV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tuning ngram_range (using best max_features and k, alpha=1.0) ---\n",
      "Using max_features=20000, k=12000\n",
      "\n",
      "Trying ngram=(1, 1)\n",
      "Validation F1-score: 0.4456\n",
      "Validation MSE: 0.8699\n",
      "\n",
      "Trying ngram=(1, 2)\n",
      "Validation F1-score: 0.4507\n",
      "Validation MSE: 0.8522\n",
      "\n",
      "Trying ngram=(1, 3)\n",
      "Validation F1-score: 0.4483\n",
      "Validation MSE: 0.8490\n",
      "\n",
      "Best ngram parameters based on MSE:\n",
      "ngram: (1, 3)\n",
      "Best Validation MSE: 0.8490\n"
     ]
    }
   ],
   "source": [
    "# --- Block 6b: Tune ngram parameter (using best max_features and k) ---\n",
    "# Define parameter grid for ngram tuning\n",
    "ngram_values = [(1,1), (1,2), (1,3)] # (2,2) and (2,3) performed poorly before\n",
    "\n",
    "# Initialize best parameters (using results from 6a if available, else defaults)\n",
    "best_ngram = None\n",
    "# Use the best MSE found in 6a as the initial benchmark if available\n",
    "best_mse_ngram = best_mse if 'best_mse' in locals() and best_mse != float('inf') else float('inf')\n",
    "# best_f1_ngram = -1.0\n",
    "\n",
    "print(\"\\n--- Tuning ngram_range (using best max_features and k, alpha=1.0) ---\")\n",
    "\n",
    "# Use best parameters found in Block 6a (or defaults if tuning failed/skipped)\n",
    "current_max_features = best_max_features if best_max_features is not None else 20000\n",
    "current_k = best_k if best_k is not None else 10000\n",
    "\n",
    "print(f\"Using max_features={current_max_features}, k={current_k}\")\n",
    "\n",
    "# Tune ngram parameter\n",
    "for ngram in ngram_values:\n",
    "    print(f\"\\nTrying ngram={ngram}\")\n",
    "\n",
    "    # Initialize vectorizer with current parameters\n",
    "    vectorizer_ngram = TfidfVectorizer(\n",
    "        max_features=current_max_features,\n",
    "        ngram_range=ngram,\n",
    "        min_df=2,\n",
    "        max_df=0.95,\n",
    "        sublinear_tf=True\n",
    "    )\n",
    "\n",
    "    # Transform training data\n",
    "    X_train_vec_ngram = vectorizer_ngram.fit_transform(X_train)\n",
    "\n",
    "    # Feature selection with best k\n",
    "    selector_ngram = SelectKBest(chi2, k=current_k)\n",
    "    X_train_selected_ngram = selector_ngram.fit_transform(X_train_vec_ngram, y_train)\n",
    "\n",
    "    # Train a simple model for evaluation (fixed alpha)\n",
    "    model_ngram = mord.LogisticAT(alpha=1.0)\n",
    "    model_ngram.fit(X_train_selected_ngram, y_train)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    X_val_vec_ngram = vectorizer_ngram.transform(X_val)\n",
    "    X_val_selected_ngram = selector_ngram.transform(X_val_vec_ngram)\n",
    "    y_val_pred_ngram = model_ngram.predict(X_val_selected_ngram)\n",
    "    f1_ngram = f1_score(y_val, y_val_pred_ngram, average='weighted')\n",
    "    mse_ngram = mean_squared_error(y_val, y_val_pred_ngram)\n",
    "\n",
    "    print(f\"Validation F1-score: {f1_ngram:.4f}\")\n",
    "    print(f\"Validation MSE: {mse_ngram:.4f}\")\n",
    "\n",
    "    # --- Select based purely on best MSE ---\n",
    "    if mse_ngram < best_mse_ngram:\n",
    "        # best_f1_ngram = f1_ngram\n",
    "        best_mse_ngram = mse_ngram\n",
    "        best_ngram = ngram\n",
    "        print(f\"New best parameters! ngram={ngram}\")\n",
    "\n",
    "# Use the best ngram found, or default if tuning failed\n",
    "final_ngram = best_ngram if best_ngram is not None else (1, 2)\n",
    "\n",
    "print(f\"\\nBest ngram parameters based on MSE:\")\n",
    "print(f\"ngram: {final_ngram}\")\n",
    "# print(f\"Best Validation F1-score (corresponding): {best_f1_ngram:.4f}\")\n",
    "print(f\"Best Validation MSE: {best_mse_ngram:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "rs2SYh5IzYzQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Applying best TF-IDF, KBest, Ngram parameters found --- \n",
      "Using: max_features=20000, k=12000, ngram_range=(1, 3)\n"
     ]
    }
   ],
   "source": [
    "# Block 7: Prepare Data with FINAL Best TF-IDF/KBest/Ngram Parameters\n",
    "print(\"\\n--- Applying best TF-IDF, KBest, Ngram parameters found --- \")\n",
    "print(f\"Using: max_features={current_max_features}, k={current_k}, ngram_range={final_ngram}\")\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=current_max_features,\n",
    "    ngram_range=final_ngram,\n",
    "    min_df=2,\n",
    "    max_df=0.95,\n",
    "    sublinear_tf=True\n",
    ")\n",
    "# Fit on training data ONLY\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "\n",
    "selector = SelectKBest(chi2, k=current_k)\n",
    "# Fit selector on training data ONLY\n",
    "X_train_selected = selector.fit_transform(X_train_vec, y_train)\n",
    "\n",
    "# Transform validation data using FITTED vectorizer and selector\n",
    "X_val_vec = vectorizer.transform(X_val)\n",
    "X_val_selected = selector.transform(X_val_vec)\n",
    "\n",
    "# Scale numerical features (Fit on train, transform train and val)\n",
    "scaler = StandardScaler()\n",
    "X_num_train_scaled = scaler.fit_transform(X_num_train)\n",
    "X_num_val_scaled = scaler.transform(X_num_val)\n",
    "\n",
    "# Combine features (No combined features used in Block 8's training loop)\n",
    "# X_train_combined = hstack([X_train_selected, X_num_train_scaled])\n",
    "# X_val_combined = hstack([X_val_selected, X_num_val_scaled])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115
    },
    "executionInfo": {
     "elapsed": 22255,
     "status": "ok",
     "timestamp": 1743078913267,
     "user": {
      "displayName": "Caleb Ong",
      "userId": "09148710192798478088"
     },
     "user_tz": -480
    },
    "id": "0GBfoac_Mz1S",
    "outputId": "02e73559-53ec-4486-a3cd-2eceb04993be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tuning alpha using cross-validation on TF-IDF features ---\n",
      "Alpha: 0.01, Mean Accuracy: 0.4248, Mean F1: 0.4252, Mean MSE: 1.1204\n",
      "Alpha: 0.1, Mean Accuracy: 0.4549, Mean F1: 0.4533, Mean MSE: 0.9256\n",
      "Alpha: 1.0, Mean Accuracy: 0.4672, Mean F1: 0.4550, Mean MSE: 0.8284\n",
      "Alpha: 5.0, Mean Accuracy: 0.4404, Mean F1: 0.4133, Mean MSE: 0.8396\n",
      "Alpha: 10.0, Mean Accuracy: 0.4151, Mean F1: 0.3842, Mean MSE: 0.8682\n",
      "\n",
      "Best alpha selected based on min MSE from training CV: 1.0\n",
      "\n",
      "--- Training final model on full training set with best alpha ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticAT()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LogisticAT<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticAT()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticAT()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Block 8: Hyperparameter Tuning for Ordinal Logistic Regression (alpha)\n",
    "print(\"\\n--- Tuning alpha using cross-validation on TF-IDF features ---\")\n",
    "# Note: Using ONLY the selected TF-IDF features (X_train_selected) for alpha tuning\n",
    "# as combining with scaled numerical features wasn't used in the original alpha tuning logic.\n",
    "# If you intended to use combined features, the loop below needs adjustment.\n",
    "\n",
    "alpha_values = [0.01, 0.1, 1.0, 5.0, 10.0] # Adjusted range slightly\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "tuning_results = []\n",
    "\n",
    "# Use KFold splits on the training data indices for alpha tuning\n",
    "train_indices = list(range(len(X_train))) # Get indices for the original training set\n",
    "\n",
    "for alpha in alpha_values:\n",
    "    fold_acc = []\n",
    "    fold_f1 = []\n",
    "    fold_mse = []\n",
    "    # Use KFold splits on the training set indices\n",
    "    for fold_train_idx, fold_val_idx in kf.split(train_indices):\n",
    "        # Select corresponding data from the *selected* training features\n",
    "        X_fold_train = X_train_selected[fold_train_idx]\n",
    "        X_fold_val = X_train_selected[fold_val_idx]\n",
    "        # Select corresponding labels from y_train using original indices\n",
    "        y_fold_train = y_train.iloc[fold_train_idx]\n",
    "        y_fold_val = y_train.iloc[fold_val_idx]\n",
    "\n",
    "        model = mord.LogisticAT(alpha=alpha)\n",
    "        model.fit(X_fold_train, y_fold_train)\n",
    "        y_val_pred = model.predict(X_fold_val) # Predict on the validation part of the fold\n",
    "\n",
    "        fold_acc.append(accuracy_score(y_fold_val, y_val_pred))\n",
    "        fold_f1.append(f1_score(y_fold_val, y_val_pred, average='weighted'))\n",
    "        fold_mse.append(mean_squared_error(y_fold_val, y_val_pred))\n",
    "\n",
    "    tuning_results.append({\n",
    "        'alpha': alpha,\n",
    "        'mean_accuracy': np.mean(fold_acc),\n",
    "        'mean_f1': np.mean(fold_f1),\n",
    "        'mean_mse': np.mean(fold_mse)\n",
    "    })\n",
    "\n",
    "# Print tuning results\n",
    "for res in tuning_results:\n",
    "    print(f\"Alpha: {res['alpha']}, Mean Accuracy: {res['mean_accuracy']:.4f}, \"\n",
    "          f\"Mean F1: {res['mean_f1']:.4f}, Mean MSE: {res['mean_mse']:.4f}\")\n",
    "\n",
    "# Select best alpha based on MSE from the cross-validation on the training set\n",
    "best_alpha = min(tuning_results, key=lambda x: x['mean_mse'])['alpha']\n",
    "print(f\"\\nBest alpha selected based on min MSE from training CV: {best_alpha}\")\n",
    "\n",
    "# --- Train final model using best_alpha on the full training set ---\n",
    "print(\"\\n--- Training final model on full training set with best alpha ---\")\n",
    "ord_model = mord.LogisticAT(alpha=best_alpha)\n",
    "# Use the X_train_selected derived from the full training data with final vectorizer/selector\n",
    "ord_model.fit(X_train_selected, y_train) # Train on the full X_train_selected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5121,
     "status": "ok",
     "timestamp": 1743078918385,
     "user": {
      "displayName": "Caleb Ong",
      "userId": "09148710192798478088"
     },
     "user_tz": -480
    },
    "id": "y0fabuBjEZ7D",
    "outputId": "8a8b0ab3-f91a-47a2-c5f0-958771762e47"
   },
   "outputs": [],
   "source": [
    "# Block 9: Save the Trained Models and Preprocessors\n",
    "with open(os.path.join(model_output_dir, 'ordinal_vectorizer.pkl'), 'wb') as f:\n",
    "    pickle.dump(vectorizer, f)\n",
    "with open(os.path.join(model_output_dir, 'ordinal_selector.pkl'), 'wb') as f:\n",
    "    pickle.dump(selector, f)\n",
    "# with open(os.path.join(model_output_dir, 'ordinal_scaler.pkl'), 'wb') as f:  # Scaler wasn't used in final combined features block\n",
    "#     pickle.dump(scaler, f)\n",
    "with open(os.path.join(model_output_dir, 'ordinal_classifier.pkl'), 'wb') as f:\n",
    "    pickle.dump(ord_model, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "twM3HBivEato"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ordinal Logistic Regression Sentiment Analysis Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.15      0.23       731\n",
      "           2       0.56      0.56      0.56      2962\n",
      "           3       0.31      0.46      0.37      1997\n",
      "           4       0.51      0.59      0.55      3029\n",
      "           5       0.57      0.17      0.26      1116\n",
      "\n",
      "    accuracy                           0.47      9835\n",
      "   macro avg       0.51      0.38      0.39      9835\n",
      "weighted avg       0.50      0.47      0.46      9835\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 106  510  101   14    0]\n",
      " [  50 1644  951  317    0]\n",
      " [  10  452  921  606    8]\n",
      " [   4  285  829 1774  137]\n",
      " [   2   42  145  738  189]]\n",
      "\n",
      "Mean Squared Error: 0.8448\n",
      "MSE for class 1: 1.4227\n",
      "MSE for class 2: 0.7660\n",
      "MSE for class 3: 0.5658\n",
      "MSE for class 4: 0.7072\n",
      "MSE for class 5: 1.5484\n"
     ]
    }
   ],
   "source": [
    "# Block 10: Evaluate the Ordinal Logistic Regression Model on the Test Set\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "X_test_selected = selector.transform(X_test_vec)\n",
    "y_pred = ord_model.predict(X_test_selected)\n",
    "\n",
    "print(\"\\nOrdinal Logistic Regression Sentiment Analysis Evaluation:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Add MSE evaluation\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"\\nMean Squared Error: {mse:.4f}\")\n",
    "\n",
    "# Add per-class MSE\n",
    "for i in range(1, 6):\n",
    "    class_mask = y_test == i\n",
    "    if any(class_mask):\n",
    "        class_mse = mean_squared_error(y_test[class_mask], y_pred[class_mask])\n",
    "        print(f\"MSE for class {i}: {class_mse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 52283,
     "status": "ok",
     "timestamp": 1743078971821,
     "user": {
      "displayName": "Caleb Ong",
      "userId": "09148710192798478088"
     },
     "user_tz": -480
    },
    "id": "OEYodNXUEa8i",
    "outputId": "e3c8dcf7-9976-4994-8bcd-77121a4a9291"
   },
   "outputs": [],
   "source": [
    "# # Block 11: Perform Inference on All Processed Files and Save Results using Ordinal Logistic Regression\n",
    "# for fname in os.listdir(processed_dir):\n",
    "#     if fname.startswith('processed_r_') and fname.endswith('.json'):\n",
    "#         file_path = os.path.join(processed_dir, fname)\n",
    "#         with open(file_path, 'r', encoding='utf-8') as f:\n",
    "#             df = pd.DataFrame(json.load(f))\n",
    "#         if 'processed_tokens_ml' not in df.columns:\n",
    "#             continue\n",
    "\n",
    "#         # Prepare text features\n",
    "#         texts = df['processed_tokens_ml'].apply(lambda toks: ' '.join(toks))\n",
    "#         X_vec = vectorizer.transform(texts)\n",
    "#         X_selected = selector.transform(X_vec)\n",
    "\n",
    "#         # Get predictions\n",
    "#         df['ordinal_sentiment'] = ord_model.predict(X_selected)\n",
    "\n",
    "#         # Calculate prediction probabilities (if available)\n",
    "#         try:\n",
    "#             df['ordinal_sentiment_prob'] = np.max(ord_model.predict_proba(X_selected), axis=1)\n",
    "#         except:\n",
    "#             df['ordinal_sentiment_prob'] = None\n",
    "\n",
    "#         # Save results\n",
    "#         out_file = fname.replace('.json', '_ordinal_sentiment.csv')\n",
    "#         out_path = os.path.join(results_output_dir, out_file)\n",
    "#         df[['id', 'title', 'ordinal_sentiment']].to_csv(out_path, index=False) # Save relevant columns\n",
    "#         print(f\"Saved: {out_file} to {results_output_dir}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
