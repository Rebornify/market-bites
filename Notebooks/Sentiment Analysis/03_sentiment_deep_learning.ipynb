{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2895,
     "status": "ok",
     "timestamp": 1743086754350,
     "user": {
      "displayName": "Caleb Ong",
      "userId": "09148710192798478088"
     },
     "user_tz": -480
    },
    "id": "_6J6Y3CdXfd0",
    "outputId": "bd34c9d3-a03f-4a82-b156-82d0991de02b"
   },
   "outputs": [],
   "source": [
    "# Block 1: Import Libraries\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, mean_squared_error\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    "    EarlyStoppingCallback\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1743086754350,
     "user": {
      "displayName": "Caleb Ong",
      "userId": "09148710192798478088"
     },
     "user_tz": -480
    },
    "id": "0wCIPIUVXfwl",
    "outputId": "12349f10-e1f9-44c3-c720-67a82ced6155"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root (Google Drive): ../../\n",
      "Looking for FinBERT input data in: ../../Data\\Historical Reddit\\FinBERT_Data\n",
      "Using golden dataset from: ../../Data\\Historical Reddit\\golden_dataset_sentiment.csv\n",
      "Saving outputs to: ../../outputs\\sentiment_analysis\\finbert\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Block 2: Define Paths for Data and Output\n",
    "\n",
    "# Define the root path of your project on Google Drive\n",
    "project_root = '../../'\n",
    "\n",
    "# Define the path to the golden dataset\n",
    "golden_path = os.path.join(project_root, 'Data', 'Historical Reddit', 'golden_dataset_sentiment.csv')\n",
    "\n",
    "# Define the specific input directory for FinBERT data\n",
    "finbert_input_dir = os.path.join(project_root, 'Data', 'Historical Reddit', 'FinBERT_Data')\n",
    "\n",
    "# Define the base output directory structure within the project root\n",
    "base_output_dir = os.path.join(project_root, 'outputs', 'sentiment_analysis', 'finbert')\n",
    "results_output_dir = os.path.join(base_output_dir, 'results')   # For saving per-subreddit predictions\n",
    "model_output_dir = os.path.join(base_output_dir, 'models')      # Optional: If saving fine-tuned models\n",
    "# evaluation_output_dir = os.path.join(base_output_dir, 'evaluations') # Optional: If saving evaluations\n",
    "\n",
    "print(f\"Project root (Google Drive): {project_root}\")\n",
    "print(f\"Looking for FinBERT input data in: {finbert_input_dir}\")\n",
    "print(f\"Using golden dataset from: {golden_path}\")\n",
    "print(f\"Saving outputs to: {base_output_dir}\") # Base output path for FinBERT Sentiment\n",
    "\n",
    "# Create all necessary output directories if they don't exist\n",
    "os.makedirs(model_output_dir, exist_ok=True)\n",
    "os.makedirs(results_output_dir, exist_ok=True)\n",
    "# os.makedirs(evaluation_output_dir, exist_ok=True) # Uncomment if needed later\n",
    "\n",
    "# Set device for PyTorch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1029,
     "status": "ok",
     "timestamp": 1743086755378,
     "user": {
      "displayName": "Caleb Ong",
      "userId": "09148710192798478088"
     },
     "user_tz": -480
    },
    "id": "hqacBKfgXhF5",
    "outputId": "61208bac-632a-42f3-8065-ddb429087a41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples in merged dataset: 49175\n",
      "Distribution of sentiment classes:\n",
      "sentiment\n",
      "1     3613\n",
      "2    14914\n",
      "3     9968\n",
      "4    15114\n",
      "5     5566\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Block 3: Load and Merge Data from JSON Files and the Golden Dataset\n",
    "dfs = []\n",
    "for fname in os.listdir(finbert_input_dir):\n",
    "    if fname.startswith('finbert_r_') and fname.endswith('.json'):\n",
    "        file_path = os.path.join(finbert_input_dir, fname)\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data_json = json.load(f)\n",
    "        df = pd.DataFrame(data_json)\n",
    "        dfs.append(df)\n",
    "all_posts = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Load the golden dataset that contains sentiment labels\n",
    "golden = pd.read_csv(golden_path)\n",
    "data = all_posts.merge(golden[['id', 'sentiment']], on='id', how='inner')\n",
    "\n",
    "# Create text field for BERT processing\n",
    "data['processed_text'] = data['processed_text_finbert']\n",
    "# Display info about dataset\n",
    "print(f\"Total samples in merged dataset: {len(data)}\")\n",
    "print(f\"Distribution of sentiment classes:\")\n",
    "print(data['sentiment'].value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 67,
     "status": "ok",
     "timestamp": 1743086755444,
     "user": {
      "displayName": "Caleb Ong",
      "userId": "09148710192798478088"
     },
     "user_tz": -480
    },
    "id": "WpQ8K77gXiaL",
    "outputId": "9256146c-73a5-431d-8f33-48b9dc826dfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 31472\n",
      "Validation samples: 7868\n",
      "Test samples: 9835\n"
     ]
    }
   ],
   "source": [
    "# Block 4: Split Data into Training, Validation, and Test Sets\n",
    "# First split: 80% train+val, 20% test\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    data['processed_text'], data['sentiment'], stratify=data['sentiment'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Second split: Split train+val into train and val\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_trainval, y_trainval, stratify=y_trainval, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create DataFrames for each split\n",
    "train_df = pd.DataFrame({'text': X_train, 'sentiment': y_train})\n",
    "val_df = pd.DataFrame({'text': X_val, 'sentiment': y_val})\n",
    "test_df = pd.DataFrame({'text': X_test, 'sentiment': y_test})\n",
    "\n",
    "print(f\"Training samples: {len(train_df)}\")\n",
    "print(f\"Validation samples: {len(val_df)}\")\n",
    "print(f\"Test samples: {len(test_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2219,
     "status": "ok",
     "timestamp": 1743086757663,
     "user": {
      "displayName": "Caleb Ong",
      "userId": "09148710192798478088"
     },
     "user_tz": -480
    },
    "id": "n2E5uo5fXjlZ",
    "outputId": "0c36e0a2-9882-44c4-933e-c2f4bd6f7931"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer loaded from yiyanghkust/finbert-tone.\n",
      "Model initialization function `model_init` defined.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Caleb\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Block 5: Load FinBERT Tokenizer and Define Model Initialization Function\n",
    "\n",
    "model_name = \"yiyanghkust/finbert-tone\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def model_init():\n",
    "    \"\"\"Initializes a fresh model for each hyperparameter trial.\"\"\"\n",
    "    # Load the base model\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "    # Resize the model's classification layer to handle 5 classes\n",
    "    # This is the most reliable way to change the output size\n",
    "    model.resize_token_embeddings(len(tokenizer))  # Ensure token embeddings match tokenizer\n",
    "    model.classifier = torch.nn.Linear(model.config.hidden_size, 5)  # Replace classifier\n",
    "    model.num_labels = 5  # Update the model's num_labels attribute\n",
    "\n",
    "    # Update the model config\n",
    "    model.config.num_labels = 5  # Update the config's num_labels\n",
    "    model.config.id2label = {0: \"1\", 1: \"2\", 2: \"3\", 3: \"4\", 4: \"5\"}\n",
    "    model.config.label2id = {\"1\": 0, \"2\": 1, \"3\": 2, \"4\": 3, \"5\": 4}\n",
    "    model.config.problem_type = \"single_label_classification\"\n",
    "\n",
    "    # Move to device\n",
    "    return model.to(device)\n",
    "\n",
    "print(f\"Tokenizer loaded from {model_name}.\")\n",
    "print(\"Model initialization function `model_init` defined.\")\n",
    "# Verify a model can be initialized (optional)\n",
    "# temp_model = model_init()\n",
    "# print(f\"Test model initialized with {temp_model.num_labels} classes.\")\n",
    "# del temp_model # Clean up memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237,
     "referenced_widgets": [
      "7ffce173ee1a4090a6564600af3c83fc",
      "f04a036d7e1d404cac72ab24db901cf2",
      "c893e863ab1840b9a44e8ef4401ea938",
      "b4800c7288fe4900bb3353d30b7c3ca2",
      "cbeea2d06b9a4242b0b8ed43eea050e4",
      "f019c61d4e0b4c3b8ba6d95866d19e33",
      "e35b962d548542259eb4a4daf6a58403",
      "4ee243a04e8b4ed99601556e25b55244",
      "8e402ca978ea4fff89129eecc608c7ef",
      "7a29029620af48609eda78230dc38dfc",
      "adbfb8d244224b2bb97cb484366d627f",
      "8107294255cc4f30be375ed662470c2a",
      "af9f24de57b44569ac8ea1062ed86d02",
      "204e284c18f74fc5b2ec06c88832061f",
      "992ba95b2f004ca69d411933ecedaa8b",
      "460ff8b269124df1aaf16fc6aee71ed1",
      "a3ce757ddabb4d7baaa904265986e111",
      "f948d03172f64387a6ef0ce8845f6404",
      "2351bbecb26a46fb94ede5998ca336d9",
      "c7199cf8b7344033960002b1de3441dc",
      "45f7fc75b3294329b5cf4f6e6cd8d9d2",
      "42aba8f772274747b3de0e2828e73711",
      "bea61497530f4fd5b3f0d4906e907520",
      "d5171001403d49c2a1b0713052259063",
      "ea470b3522b54b09b959740aa9f6c65d",
      "c3dd5e06a30844dd834fb1339a3397d8",
      "2298a3f71aa14bbc836223c5eccd0cf9",
      "74a6e0a4d871481795aea2763a7fca6e",
      "f9c0d241c2644771a09bd212f4e33722",
      "c965b82d20a04641aa293fe21711b2cd",
      "531470892f9b48618a2b07de9c30e7b8",
      "49e65535ace34301b5702fb99f96b0f2",
      "c628ecac5d0740b7a9059481d8b2c5a6"
     ]
    },
    "executionInfo": {
     "elapsed": 59906,
     "status": "ok",
     "timestamp": 1743086817620,
     "user": {
      "displayName": "Caleb Ong",
      "userId": "09148710192798478088"
     },
     "user_tz": -480
    },
    "id": "kvvKZWpKXmSL",
    "outputId": "d5c6468b-c5d0-415e-8a35-4f2465249bff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample from dataset:\n",
      "{'text': 'Be Careful Out There Folks: It is Beginning to Feel a Lot More Like 2017 (SAFE.. This, Finance... That) Mirroring Old ICO Days Do not be left holding worthless bags! Without mincing words, the current state of the cryptocurrency market is looking no different from what it was in late 2017, just before the bubble burst and people went back to their normal lives like crypto never existed. There were shiny ICOs and whitepapers here and there and hundreds of tokens being released every day, sometimes on websites with fake photos of humans that exist nowhere. Today, we are living a reminiscence with many shit projects hitting under the umbrella of Defi, .Finance domain websites, and practically no live product. Do not get me wrong, I like and do DeFi, but there are just so many scams out there and new investors will get burned when all of this euphoria ends. Worse is the recent proliferation of meme coins claiming to be the next doge and that investors can make 50x-100x holding a coin that has no use case, and communities that are less than a week old, without everyone looking to cash out and run. Token supply runs into trillions and you can get 100 billion coins with just $5. Really? I am talking about all these SAFE... this, Doge that, Elon (gate), Shiba trash, etc. If you are a new investor, it would be best to stay out of these trash coins or protect any profits you have made so far. Ask anyone who lived in the 2017 ICO era, and maybe their stories will make you wise up. The longer this trend continues, the harder the fall will be and the closer we will be to another market. You do not want to be left holding billions of worthless tokens!', 'sentiment': 2, '__index_level_0__': 8421}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9b7938b6fbe442e86ff990cef8828a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/31472 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "149b6cc7ddb34f46b4f07324d48d0cd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7868 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "717e18ad5f49438fb22a095924535035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9835 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample after preprocessing:\n",
      "{'text': 'Be Careful Out There Folks: It is Beginning to Feel a Lot More Like 2017 (SAFE.. This, Finance... That) Mirroring Old ICO Days Do not be left holding worthless bags! Without mincing words, the current state of the cryptocurrency market is looking no different from what it was in late 2017, just before the bubble burst and people went back to their normal lives like crypto never existed. There were shiny ICOs and whitepapers here and there and hundreds of tokens being released every day, sometimes on websites with fake photos of humans that exist nowhere. Today, we are living a reminiscence with many shit projects hitting under the umbrella of Defi, .Finance domain websites, and practically no live product. Do not get me wrong, I like and do DeFi, but there are just so many scams out there and new investors will get burned when all of this euphoria ends. Worse is the recent proliferation of meme coins claiming to be the next doge and that investors can make 50x-100x holding a coin that has no use case, and communities that are less than a week old, without everyone looking to cash out and run. Token supply runs into trillions and you can get 100 billion coins with just $5. Really? I am talking about all these SAFE... this, Doge that, Elon (gate), Shiba trash, etc. If you are a new investor, it would be best to stay out of these trash coins or protect any profits you have made so far. Ask anyone who lived in the 2017 ICO era, and maybe their stories will make you wise up. The longer this trend continues, the harder the fall will be and the closer we will be to another market. You do not want to be left holding billions of worthless tokens!', 'sentiment': 2, '__index_level_0__': 8421, 'input_ids': [3, 25, 9052, 263, 112, 5921, 3108, 41, 17, 745, 9, 1365, 11, 605, 59, 266, 581, 333, 2320, 48, 48, 26, 585, 891, 48, 48, 48, 15, 765, 10001, 223, 2664, 4604, 688, 863, 123, 30, 25, 3534, 950, 2332, 4770, 19039, 17293, 401, 9499, 8467, 3032, 585, 6, 140, 416, 7, 6, 23912, 16807, 15031, 52, 17, 601, 141, 526, 23, 163, 41, 35, 10, 1439, 581, 585, 160, 379, 6, 19358, 7710, 2031, 8, 1043, 2831, 385, 9, 104, 1334, 3424, 266, 23912, 16807, 2824, 11068, 48, 112, 57, 14929, 387, 4604, 2986, 8, 3797, 4085, 13936, 1094, 8, 112, 8, 10353, 7, 24231, 9335, 304, 2688, 1214, 1037, 585, 3611, 19, 5031, 20, 9455, 3349, 16514, 7, 17920, 15, 4385, 212, 17190, 48, 1163, 585, 13, 21, 4241, 11, 20271, 14459, 21238, 2078, 20, 321, 11125, 463, 923, 9892, 82, 6, 15716, 7, 18389, 585, 48, 891, 5301, 5031, 585, 8, 8374, 724, 141, 3209, 108, 48, 123, 30, 391, 914, 8231, 585, 44, 266, 8, 123, 18389, 585, 71, 112, 21, 160, 96, 321, 15364, 4391, 263, 112, 8, 56, 311, 36, 391, 23243, 251, 181, 69, 7, 26, 3484, 13197, 8566, 4276, 48, 3764, 17, 6, 399, 14683, 7, 13541, 246, 29114, 14769, 9, 25, 6, 165, 22559, 246, 8, 15, 311, 110, 235, 1104, 456, 85, 1081, 456, 950, 11, 17642, 15, 49, 141, 194, 781, 585, 8, 3008, 15, 21, 314, 74, 11, 1952, 2664, 585, 401, 2588, 601, 9, 50, 263, 8, 1415, 48, 24231, 1781, 4], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': 1}\n",
      "Label range: min=0, max=4\n"
     ]
    }
   ],
   "source": [
    "# Block 6: Prepare Datasets for the Transformer Model\n",
    "def preprocess_function(examples):\n",
    "    # Tokenize the texts and prepare for the model\n",
    "    result = tokenizer(\n",
    "        examples['text'],\n",
    "        truncation=True,\n",
    "        max_length=256,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    # Convert 1-5 sentiment labels to 0-4 for the model (0-indexed)\n",
    "    result[\"labels\"] = [label - 1 for label in examples['sentiment']]\n",
    "    return result\n",
    "\n",
    "# Convert pandas DataFrames to HuggingFace Datasets\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# Look at a sample to verify the data structure\n",
    "print(\"Sample from dataset:\")\n",
    "print(train_dataset[0])\n",
    "\n",
    "# Apply preprocessing\n",
    "train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "val_dataset = val_dataset.map(preprocess_function, batched=True)\n",
    "test_dataset = test_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "# Check processed data\n",
    "print(\"\\nSample after preprocessing:\")\n",
    "print(train_dataset[0])\n",
    "print(f\"Label range: min={min(train_dataset['labels'])}, max={max(train_dataset['labels'])}\")\n",
    "\n",
    "# Set the format for PyTorch\n",
    "train_dataset.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
    "val_dataset.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
    "test_dataset.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "# Data collator for dynamic padding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1743086947535,
     "user": {
      "displayName": "Caleb Ong",
      "userId": "09148710192798478088"
     },
     "user_tz": -480
    },
    "id": "Iuq8cDtfsdfI",
    "outputId": "f29c06fb-2d76-468f-866d-805872f5e824"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingArguments configured for reduced logging.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Caleb\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Block 7: Define Training Arguments and Metrics Function\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    # Convert back to 1-5 scale for evaluation\n",
    "    predictions_1to5 = predictions + 1\n",
    "    labels_1to5 = labels + 1\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = (predictions == labels).mean()\n",
    "    weighted_f1 = f1_score(labels_1to5, predictions_1to5, average='weighted')\n",
    "    mse = mean_squared_error(labels_1to5, predictions_1to5)\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'weighted_f1': weighted_f1,\n",
    "        'mse': mse\n",
    "    }\n",
    "\n",
    "# Set training arguments with less logging\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./finbert_finetuned\",\n",
    "    # --- Reduced Logging ---\n",
    "    logging_dir='./logs',        # Keep log directory\n",
    "    logging_strategy=\"epoch\",    # Log at the end of each epoch\n",
    "    disable_tqdm=True,           # Disable detailed progress bars for cleaner output\n",
    "    report_to=[\"none\"],          # Disable external reporting (like wandb)\n",
    "    # --- Evaluation and Saving ---\n",
    "    evaluation_strategy=\"epoch\", # Evaluate at the end of each epoch\n",
    "    save_strategy=\"epoch\",       # Save model at the end of each epoch\n",
    "    load_best_model_at_end=True, # Load the best model found during training\n",
    "    metric_for_best_model=\"weighted_f1\", # Use weighted_f1 to determine the best model\n",
    "    greater_is_better=True,\n",
    "    # --- Other Training Parameters ---\n",
    "    num_train_epochs=3, # Default epochs (will be overridden by hyperparameter search)\n",
    "    per_device_train_batch_size=16, # Default batch size (will be overridden)\n",
    "    per_device_eval_batch_size=16,  # Default eval batch size (will be linked to train size during search)\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.01,\n",
    "    fp16=torch.cuda.is_available(), # Use mixed precision if GPU available\n",
    ")\n",
    "\n",
    "print(\"TrainingArguments configured for reduced logging.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 239
    },
    "executionInfo": {
     "elapsed": 1396460,
     "status": "ok",
     "timestamp": 1743088346383,
     "user": {
      "displayName": "Caleb Ong",
      "userId": "09148710192798478088"
     },
     "user_tz": -480
    },
    "id": "MJEIOK-QuY3m",
    "outputId": "a2368ccc-d989-4dda-f23a-60613f3887cd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-08 15:40:14,761] A new study created in memory with name: no-name-46878936-912a-47ab-a0b5-20cb7837bf4e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hyperparameter search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Caleb\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2007, 'grad_norm': 7.9891180992126465, 'learning_rate': 4.104864579076952e-06, 'epoch': 1.0}\n",
      "{'eval_loss': 1.0374835729599, 'eval_accuracy': 0.5638027452974073, 'eval_weighted_f1': 0.5539302016816158, 'eval_mse': 0.8942552109811897, 'eval_runtime': 22.3269, 'eval_samples_per_second': 352.399, 'eval_steps_per_second': 22.036, 'epoch': 1.0}\n",
      "{'loss': 0.9885, 'grad_norm': 16.531944274902344, 'learning_rate': 2.737967629765613e-06, 'epoch': 2.0}\n",
      "{'eval_loss': 0.9953482747077942, 'eval_accuracy': 0.5878240976105745, 'eval_weighted_f1': 0.5784566894285187, 'eval_mse': 0.8462125063548551, 'eval_runtime': 21.8089, 'eval_samples_per_second': 360.771, 'eval_steps_per_second': 22.56, 'epoch': 2.0}\n",
      "{'loss': 0.8974, 'grad_norm': 11.49541187286377, 'learning_rate': 1.3703750585971182e-06, 'epoch': 3.0}\n",
      "{'eval_loss': 0.9971779584884644, 'eval_accuracy': 0.5884595831215048, 'eval_weighted_f1': 0.582159351168216, 'eval_mse': 0.8160904931367565, 'eval_runtime': 22.1168, 'eval_samples_per_second': 355.747, 'eval_steps_per_second': 22.246, 'epoch': 3.0}\n",
      "{'loss': 0.8318, 'grad_norm': 14.730746269226074, 'learning_rate': 2.7824874286235904e-09, 'epoch': 4.0}\n",
      "{'eval_loss': 1.0033468008041382, 'eval_accuracy': 0.5931621759023894, 'eval_weighted_f1': 0.5891938899432824, 'eval_mse': 0.8080833756990341, 'eval_runtime': 22.4529, 'eval_samples_per_second': 350.422, 'eval_steps_per_second': 21.913, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-08 16:03:05,888] Trial 0 finished with value: 1.990439441544706 and parameters: {'learning_rate': 4.925698370520911e-06, 'num_train_epochs': 4, 'per_device_train_batch_size': 16}. Best is trial 0 with value: 1.990439441544706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1369.7743, 'train_samples_per_second': 91.904, 'train_steps_per_second': 5.744, 'train_loss': 0.9795921027024022, 'epoch': 4.0}\n",
      "{'loss': 1.1782, 'grad_norm': 8.861656188964844, 'learning_rate': 2.619500977385232e-06, 'epoch': 1.0}\n",
      "{'eval_loss': 1.0437047481536865, 'eval_accuracy': 0.5622775800711743, 'eval_weighted_f1': 0.5524934865253643, 'eval_mse': 0.9070920183019827, 'eval_runtime': 22.1205, 'eval_samples_per_second': 355.689, 'eval_steps_per_second': 22.242, 'epoch': 1.0}\n",
      "{'loss': 0.997, 'grad_norm': 16.76319122314453, 'learning_rate': 2.6620944892126343e-09, 'epoch': 2.0}\n",
      "{'eval_loss': 1.0202585458755493, 'eval_accuracy': 0.5748601931875953, 'eval_weighted_f1': 0.5676926426268532, 'eval_mse': 0.874936451448907, 'eval_runtime': 22.2627, 'eval_samples_per_second': 353.417, 'eval_steps_per_second': 22.1, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-08 16:14:38,205] Trial 1 finished with value: 2.0174892872633556 and parameters: {'learning_rate': 4.711907245906362e-06, 'num_train_epochs': 2, 'per_device_train_batch_size': 16}. Best is trial 1 with value: 2.0174892872633556.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 691.4695, 'train_samples_per_second': 91.029, 'train_steps_per_second': 5.689, 'train_loss': 1.0876436917140633, 'epoch': 2.0}\n",
      "{'loss': 1.1548, 'grad_norm': 6.6695051193237305, 'learning_rate': 1.3133695625411714e-05, 'epoch': 1.0}\n",
      "{'eval_loss': 1.0336283445358276, 'eval_accuracy': 0.5707930859176411, 'eval_weighted_f1': 0.554256717995848, 'eval_mse': 0.8104982206405694, 'eval_runtime': 22.0818, 'eval_samples_per_second': 356.312, 'eval_steps_per_second': 22.281, 'epoch': 1.0}\n",
      "{'loss': 0.8933, 'grad_norm': 17.87555694580078, 'learning_rate': 9.852358022214431e-06, 'epoch': 2.0}\n",
      "{'eval_loss': 0.9710701704025269, 'eval_accuracy': 0.6072699542450433, 'eval_weighted_f1': 0.6014555378054353, 'eval_mse': 0.7714794102694459, 'eval_runtime': 22.1039, 'eval_samples_per_second': 355.955, 'eval_steps_per_second': 22.259, 'epoch': 2.0}\n",
      "{'loss': 0.6795, 'grad_norm': 16.667139053344727, 'learning_rate': 6.5710204190171456e-06, 'epoch': 3.0}\n",
      "{'eval_loss': 1.0387054681777954, 'eval_accuracy': 0.6066344687341129, 'eval_weighted_f1': 0.6035972027079822, 'eval_mse': 0.7676664972038637, 'eval_runtime': 21.9014, 'eval_samples_per_second': 359.246, 'eval_steps_per_second': 22.464, 'epoch': 3.0}\n",
      "{'loss': 0.4943, 'grad_norm': 13.33307933807373, 'learning_rate': 3.2896828158198615e-06, 'epoch': 4.0}\n",
      "{'eval_loss': 1.1555492877960205, 'eval_accuracy': 0.6124809354346721, 'eval_weighted_f1': 0.6087837685235661, 'eval_mse': 0.7393238434163701, 'eval_runtime': 22.3177, 'eval_samples_per_second': 352.545, 'eval_steps_per_second': 22.045, 'epoch': 4.0}\n",
      "{'loss': 0.3715, 'grad_norm': 24.067655563354492, 'learning_rate': 8.34521262257702e-09, 'epoch': 5.0}\n",
      "{'eval_loss': 1.3062869310379028, 'eval_accuracy': 0.6072699542450433, 'eval_weighted_f1': 0.6069555409856355, 'eval_mse': 0.7105998983223183, 'eval_runtime': 22.341, 'eval_samples_per_second': 352.178, 'eval_steps_per_second': 22.022, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-08 16:43:07,174] Trial 2 finished with value: 1.924825393552997 and parameters: {'learning_rate': 1.477269538448584e-05, 'num_train_epochs': 5, 'per_device_train_batch_size': 16}. Best is trial 1 with value: 2.0174892872633556.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1708.0781, 'train_samples_per_second': 92.127, 'train_steps_per_second': 5.758, 'train_loss': 0.7186684294769954, 'epoch': 5.0}\n",
      "{'loss': 1.1299, 'grad_norm': 6.544529914855957, 'learning_rate': 2.527768512690331e-05, 'epoch': 1.0}\n",
      "{'eval_loss': 1.0242236852645874, 'eval_accuracy': 0.5734621250635485, 'eval_weighted_f1': 0.5540170985690781, 'eval_mse': 0.838840874428063, 'eval_runtime': 22.1013, 'eval_samples_per_second': 355.997, 'eval_steps_per_second': 22.261, 'epoch': 1.0}\n",
      "{'loss': 0.8403, 'grad_norm': 17.557580947875977, 'learning_rate': 1.68575006200426e-05, 'epoch': 2.0}\n",
      "{'eval_loss': 0.9758158326148987, 'eval_accuracy': 0.6096847991865786, 'eval_weighted_f1': 0.6025341302268693, 'eval_mse': 0.7594051855617692, 'eval_runtime': 23.2171, 'eval_samples_per_second': 338.889, 'eval_steps_per_second': 21.191, 'epoch': 2.0}\n",
      "{'loss': 0.5469, 'grad_norm': 15.823457717895508, 'learning_rate': 8.437316113181891e-06, 'epoch': 3.0}\n",
      "{'eval_loss': 1.140053391456604, 'eval_accuracy': 0.6043467208947636, 'eval_weighted_f1': 0.6015677474797774, 'eval_mse': 0.7468225724453482, 'eval_runtime': 22.9657, 'eval_samples_per_second': 342.598, 'eval_steps_per_second': 21.423, 'epoch': 3.0}\n",
      "{'loss': 0.3122, 'grad_norm': 19.835182189941406, 'learning_rate': 1.7131606321181504e-08, 'epoch': 4.0}\n",
      "{'eval_loss': 1.4004082679748535, 'eval_accuracy': 0.6140061006609049, 'eval_weighted_f1': 0.6133333440813857, 'eval_mse': 0.6836553126588714, 'eval_runtime': 22.145, 'eval_samples_per_second': 355.294, 'eval_steps_per_second': 22.217, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-08 17:06:30,910] Trial 3 finished with value: 1.9109947574011619 and parameters: {'learning_rate': 3.0327226090071557e-05, 'num_train_epochs': 4, 'per_device_train_batch_size': 16}. Best is trial 1 with value: 2.0174892872633556.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1402.8735, 'train_samples_per_second': 89.736, 'train_steps_per_second': 5.608, 'train_loss': 0.7073396295839357, 'epoch': 4.0}\n",
      "{'loss': 1.2054, 'grad_norm': 14.891928672790527, 'learning_rate': 1.2500083223165004e-06, 'epoch': 1.0}\n",
      "{'eval_loss': 1.0683526992797852, 'eval_accuracy': 0.5565582104728012, 'eval_weighted_f1': 0.5398929372761283, 'eval_mse': 0.9027707168276563, 'eval_runtime': 21.7933, 'eval_samples_per_second': 361.029, 'eval_steps_per_second': 22.576, 'epoch': 1.0}\n",
      "{'loss': 1.0386, 'grad_norm': 24.194337844848633, 'learning_rate': 9.527502456680644e-10, 'epoch': 2.0}\n",
      "{'eval_loss': 1.047190546989441, 'eval_accuracy': 0.5654550076258261, 'eval_weighted_f1': 0.5558092640218915, 'eval_mse': 0.900482968988307, 'eval_runtime': 22.2502, 'eval_samples_per_second': 353.615, 'eval_steps_per_second': 22.112, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-08 17:20:48,715] Trial 4 finished with value: 2.0217472406360244 and parameters: {'learning_rate': 2.2488081631918547e-06, 'num_train_epochs': 2, 'per_device_train_batch_size': 8}. Best is trial 4 with value: 2.0217472406360244.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 856.783, 'train_samples_per_second': 73.466, 'train_steps_per_second': 9.183, 'train_loss': 1.1219899769537207, 'epoch': 2.0}\n",
      "\n",
      "Hyperparameter search finished.\n",
      "Best trial found:\n",
      "  Value (eval_weighted_f1): 2.0217472406360244\n",
      "  Params: {'learning_rate': 2.2488081631918547e-06, 'num_train_epochs': 2, 'per_device_train_batch_size': 8}\n",
      "\n",
      "Training final model with the best hyperparameters found...\n",
      "{'loss': 1.2022, 'grad_norm': 13.969533920288086, 'learning_rate': 1.2500083223165004e-06, 'epoch': 1.0}\n",
      "{'eval_loss': 1.0687209367752075, 'eval_accuracy': 0.5537620742247077, 'eval_weighted_f1': 0.541377037935951, 'eval_mse': 0.9203101169293341, 'eval_runtime': 26.51, 'eval_samples_per_second': 296.793, 'eval_steps_per_second': 37.118, 'epoch': 1.0}\n",
      "{'loss': 1.036, 'grad_norm': 26.22003746032715, 'learning_rate': 1.2703336608907526e-09, 'epoch': 2.0}\n",
      "{'eval_loss': 1.0493544340133667, 'eval_accuracy': 0.5704117946110828, 'eval_weighted_f1': 0.5624692667652869, 'eval_mse': 0.9065836298932385, 'eval_runtime': 26.1148, 'eval_samples_per_second': 301.285, 'eval_steps_per_second': 37.68, 'epoch': 2.0}\n",
      "{'train_runtime': 868.5353, 'train_samples_per_second': 72.471, 'train_steps_per_second': 9.059, 'train_loss': 1.1191292061197256, 'epoch': 2.0}\n",
      "Final model trained with best hyperparameters saved to ../../outputs\\sentiment_analysis\\finbert\\models\\finbert_finetuned_best_hparams\n"
     ]
    }
   ],
   "source": [
    "# Block 8: Initialize Trainer and Run Hyperparameter Search (with Reduced Logging)\n",
    "\n",
    "# --- Initialize Trainer using model_init ---\n",
    "trainer = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    # Stops training if 'weighted_f1' doesn't improve for 3 evaluation steps.\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "# --- Define the Hyperparameter Space for Optuna ---\n",
    "def optuna_hp_space(trial):\n",
    "  \"\"\"Defines the hyperparameter search space for Optuna.\"\"\"\n",
    "  return {\n",
    "      \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-6, 1e-4, log=True),\n",
    "      \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 2, 5),\n",
    "      \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [8, 16]),\n",
    "  }\n",
    "\n",
    "# ---  Set Optuna's logging verbosity ---\n",
    "optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "\n",
    "# --- Run Hyperparameter Search ---\n",
    "print(\"Starting hyperparameter search...\")\n",
    "best_trial = trainer.hyperparameter_search(\n",
    "    direction=\"maximize\",\n",
    "    backend=\"optuna\",\n",
    "    hp_space=optuna_hp_space,\n",
    "    n_trials=5\n",
    ")\n",
    "\n",
    "print(\"\\nHyperparameter search finished.\")\n",
    "print(f\"Best trial found:\")\n",
    "print(f\"  Value (eval_weighted_f1): {best_trial.objective}\")\n",
    "print(f\"  Params: {best_trial.hyperparameters}\")\n",
    "\n",
    "# --- Train Final Model with Best Hyperparameters ---\n",
    "print(\"\\nTraining final model with the best hyperparameters found...\")\n",
    "best_params = best_trial.hyperparameters\n",
    "for param, value in best_params.items():\n",
    "    if param == \"per_device_train_batch_size\":\n",
    "        setattr(training_args, \"per_device_eval_batch_size\", value)\n",
    "    setattr(training_args, param, value)\n",
    "\n",
    "# Update args to disable tqdm for final training too\n",
    "setattr(training_args, \"disable_tqdm\", True)\n",
    "\n",
    "final_model = model_init()\n",
    "trainer = Trainer(\n",
    "    model=final_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    # Add callback here too for the final training run\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "model_save_path = os.path.join(model_output_dir, \"finbert_finetuned_best_hparams\")\n",
    "trainer.save_model(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "print(f\"Final model trained with best hyperparameters saved to {model_save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 540
    },
    "executionInfo": {
     "elapsed": 68445,
     "status": "ok",
     "timestamp": 1743088809890,
     "user": {
      "displayName": "Caleb Ong",
      "userId": "09148710192798478088"
     },
     "user_tz": -480
    },
    "id": "DSjih_G_ua7K",
    "outputId": "0a42d70e-783d-403d-9f35-a5e0f24e0ba8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set...\n",
      "{'eval_loss': 1.054720401763916, 'eval_accuracy': 0.5630910015251652, 'eval_weighted_f1': 0.5542054329863343, 'eval_mse': 0.9019827147941027, 'eval_runtime': 32.7867, 'eval_samples_per_second': 299.97, 'eval_steps_per_second': 37.515, 'epoch': 2.0}\n",
      "Test set evaluation results:\n",
      "{'eval_loss': 1.054720401763916, 'eval_accuracy': 0.5630910015251652, 'eval_weighted_f1': 0.5542054329863343, 'eval_mse': 0.9019827147941027, 'eval_runtime': 32.7867, 'eval_samples_per_second': 299.97, 'eval_steps_per_second': 37.515, 'epoch': 2.0}\n",
      "\n",
      "FinBERT Deep Learning Sentiment Analysis Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.27      0.36       723\n",
      "           2       0.56      0.71      0.62      2983\n",
      "           3       0.56      0.44      0.49      1993\n",
      "           4       0.56      0.62      0.59      3023\n",
      "           5       0.63      0.44      0.52      1113\n",
      "\n",
      "    accuracy                           0.56      9835\n",
      "   macro avg       0.57      0.50      0.52      9835\n",
      "weighted avg       0.56      0.56      0.55      9835\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 197  479    5   40    2]\n",
      " [ 141 2119  331  372   20]\n",
      " [   9  539  871  549   25]\n",
      " [  15  569  339 1860  240]\n",
      " [  10  100   18  494  491]]\n",
      "\n",
      "Mean Squared Error: 0.9020\n",
      "MSE for class 1: 1.2324\n",
      "MSE for class 2: 0.7174\n",
      "MSE for class 3: 0.6141\n",
      "MSE for class 4: 0.9891\n",
      "MSE for class 5: 1.4609\n"
     ]
    }
   ],
   "source": [
    "# Block 9: Evaluate the Fine-tuned Model on Test Set\n",
    "print(\"Evaluating on test set...\")\n",
    "eval_results = trainer.evaluate(test_dataset)\n",
    "print(f\"Test set evaluation results:\\n{eval_results}\")\n",
    "\n",
    "# Get predictions for confusion matrix and detailed metrics\n",
    "predictions = trainer.predict(test_dataset)\n",
    "preds = np.argmax(predictions.predictions, axis=1)\n",
    "labels = predictions.label_ids\n",
    "\n",
    "# Convert back to 1-5 scale\n",
    "preds_1to5 = preds + 1\n",
    "labels_1to5 = labels + 1\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nFinBERT Deep Learning Sentiment Analysis Evaluation:\")\n",
    "print(classification_report(labels_1to5, preds_1to5))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(labels_1to5, preds_1to5))\n",
    "\n",
    "# Calculate MSE\n",
    "mse = mean_squared_error(labels_1to5, preds_1to5)\n",
    "print(f\"\\nMean Squared Error: {mse:.4f}\")\n",
    "\n",
    "# Calculate per-class MSE\n",
    "for i in range(1, 6):\n",
    "    class_mask = labels_1to5 == i\n",
    "    if np.any(class_mask):\n",
    "        class_mse = mean_squared_error(labels_1to5[class_mask], preds_1to5[class_mask])\n",
    "        print(f\"MSE for class {i}: {class_mse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "SCsz7YQWucPh"
   },
   "outputs": [],
   "source": [
    "# Block 10: Batch Prediction Function for JSON Files\n",
    "def predict_batch(texts, model, tokenizer, device, batch_size=32):\n",
    "    \"\"\"Process a list of texts in batches and return predictions\"\"\"\n",
    "    all_predictions = []\n",
    "    all_scores = []\n",
    "\n",
    "    # Process in batches\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "\n",
    "        # Tokenize\n",
    "        inputs = tokenizer(\n",
    "            batch_texts,\n",
    "            truncation=True,\n",
    "            max_length=256,\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "\n",
    "        # Get predictions\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
    "\n",
    "        # Convert to CPU for numpy operations\n",
    "        preds = torch.argmax(logits, dim=-1).cpu().numpy()\n",
    "        scores = torch.max(probabilities, dim=-1).values.cpu().numpy()\n",
    "\n",
    "        # Convert predictions back to 1-5 scale\n",
    "        preds = preds + 1\n",
    "\n",
    "        all_predictions.extend(preds)\n",
    "        all_scores.extend(scores)\n",
    "\n",
    "    return all_predictions, all_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1743088929967,
     "user": {
      "displayName": "Caleb Ong",
      "userId": "09148710192798478088"
     },
     "user_tz": -480
    },
    "id": "gdM16fOZueh-",
    "outputId": "09ffe437-1f58-4ad0-b3c0-384403808e01"
   },
   "outputs": [],
   "source": [
    "# # Block 11: Perform Inference on All Processed Files and Save Results\n",
    "# print(\"Performing inference on all processed files...\")\n",
    "# model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# for fname in os.listdir(finbert_input_dir):\n",
    "#     if fname.startswith('processed_r_') and fname.endswith('.json'):\n",
    "#         file_path = os.path.join(finbert_input_dir, fname)\n",
    "\n",
    "#         print(f\"Processing {fname}...\")\n",
    "\n",
    "#         with open(file_path, 'r', encoding='utf-8') as f:\n",
    "#             df = pd.DataFrame(json.load(f))\n",
    "\n",
    "#         if 'processed_tokens_ml' not in df.columns:\n",
    "#             continue\n",
    "\n",
    "#         # Prepare text for model\n",
    "#         texts = df['processed_tokens_ml'].apply(lambda toks: ' '.join(toks)).tolist()\n",
    "\n",
    "#         # Get predictions in batches\n",
    "#         predictions, scores = predict_batch(texts, model, tokenizer, device)\n",
    "\n",
    "#         # Add to DataFrame\n",
    "#         df['finbert_sentiment'] = predictions\n",
    "#         df['finbert_confidence'] = scores\n",
    "\n",
    "#         # Save results\n",
    "#         out_file = fname.replace('.json', '_finbert_sentiment.csv')\n",
    "#         out_path = os.path.join(output_dir, out_file)\n",
    "#         df.to_csv(out_path, index=False)\n",
    "#         print(f\"Saved: {out_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNPWfmzhZ6cR6YaMa8wn4ZO",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "204e284c18f74fc5b2ec06c88832061f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2351bbecb26a46fb94ede5998ca336d9",
      "max": 7868,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c7199cf8b7344033960002b1de3441dc",
      "value": 7868
     }
    },
    "2298a3f71aa14bbc836223c5eccd0cf9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2351bbecb26a46fb94ede5998ca336d9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "42aba8f772274747b3de0e2828e73711": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "45f7fc75b3294329b5cf4f6e6cd8d9d2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "460ff8b269124df1aaf16fc6aee71ed1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "49e65535ace34301b5702fb99f96b0f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4ee243a04e8b4ed99601556e25b55244": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "531470892f9b48618a2b07de9c30e7b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "74a6e0a4d871481795aea2763a7fca6e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a29029620af48609eda78230dc38dfc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7ffce173ee1a4090a6564600af3c83fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f04a036d7e1d404cac72ab24db901cf2",
       "IPY_MODEL_c893e863ab1840b9a44e8ef4401ea938",
       "IPY_MODEL_b4800c7288fe4900bb3353d30b7c3ca2"
      ],
      "layout": "IPY_MODEL_cbeea2d06b9a4242b0b8ed43eea050e4"
     }
    },
    "8107294255cc4f30be375ed662470c2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_af9f24de57b44569ac8ea1062ed86d02",
       "IPY_MODEL_204e284c18f74fc5b2ec06c88832061f",
       "IPY_MODEL_992ba95b2f004ca69d411933ecedaa8b"
      ],
      "layout": "IPY_MODEL_460ff8b269124df1aaf16fc6aee71ed1"
     }
    },
    "8e402ca978ea4fff89129eecc608c7ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "992ba95b2f004ca69d411933ecedaa8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_45f7fc75b3294329b5cf4f6e6cd8d9d2",
      "placeholder": "​",
      "style": "IPY_MODEL_42aba8f772274747b3de0e2828e73711",
      "value": " 7868/7868 [00:10&lt;00:00, 687.16 examples/s]"
     }
    },
    "a3ce757ddabb4d7baaa904265986e111": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "adbfb8d244224b2bb97cb484366d627f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "af9f24de57b44569ac8ea1062ed86d02": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a3ce757ddabb4d7baaa904265986e111",
      "placeholder": "​",
      "style": "IPY_MODEL_f948d03172f64387a6ef0ce8845f6404",
      "value": "Map: 100%"
     }
    },
    "b4800c7288fe4900bb3353d30b7c3ca2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7a29029620af48609eda78230dc38dfc",
      "placeholder": "​",
      "style": "IPY_MODEL_adbfb8d244224b2bb97cb484366d627f",
      "value": " 31472/31472 [00:37&lt;00:00, 888.37 examples/s]"
     }
    },
    "bea61497530f4fd5b3f0d4906e907520": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d5171001403d49c2a1b0713052259063",
       "IPY_MODEL_ea470b3522b54b09b959740aa9f6c65d",
       "IPY_MODEL_c3dd5e06a30844dd834fb1339a3397d8"
      ],
      "layout": "IPY_MODEL_2298a3f71aa14bbc836223c5eccd0cf9"
     }
    },
    "c3dd5e06a30844dd834fb1339a3397d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_49e65535ace34301b5702fb99f96b0f2",
      "placeholder": "​",
      "style": "IPY_MODEL_c628ecac5d0740b7a9059481d8b2c5a6",
      "value": " 9835/9835 [00:11&lt;00:00, 779.19 examples/s]"
     }
    },
    "c628ecac5d0740b7a9059481d8b2c5a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c7199cf8b7344033960002b1de3441dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c893e863ab1840b9a44e8ef4401ea938": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4ee243a04e8b4ed99601556e25b55244",
      "max": 31472,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8e402ca978ea4fff89129eecc608c7ef",
      "value": 31472
     }
    },
    "c965b82d20a04641aa293fe21711b2cd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cbeea2d06b9a4242b0b8ed43eea050e4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d5171001403d49c2a1b0713052259063": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_74a6e0a4d871481795aea2763a7fca6e",
      "placeholder": "​",
      "style": "IPY_MODEL_f9c0d241c2644771a09bd212f4e33722",
      "value": "Map: 100%"
     }
    },
    "e35b962d548542259eb4a4daf6a58403": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ea470b3522b54b09b959740aa9f6c65d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c965b82d20a04641aa293fe21711b2cd",
      "max": 9835,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_531470892f9b48618a2b07de9c30e7b8",
      "value": 9835
     }
    },
    "f019c61d4e0b4c3b8ba6d95866d19e33": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f04a036d7e1d404cac72ab24db901cf2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f019c61d4e0b4c3b8ba6d95866d19e33",
      "placeholder": "​",
      "style": "IPY_MODEL_e35b962d548542259eb4a4daf6a58403",
      "value": "Map: 100%"
     }
    },
    "f948d03172f64387a6ef0ce8845f6404": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f9c0d241c2644771a09bd212f4e33722": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
