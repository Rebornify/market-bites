{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from openai import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide your OpenAI API key\n",
    "# WARNING: Storing API keys directly in code is not recommended for production.\n",
    "# Consider using environment variables or a secure key management system.\n",
    "api_key = \"\"\n",
    "client = OpenAI(api_key=api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Paths for Data and Output\n",
    "project_root = '/content/drive/MyDrive/IS450 Project'\n",
    "input_json_path = os.path.join(project_root, 'Data', 'Historical Reddit', 'NER', 'Unlabeled', '5000_reddit_posts_for_NER.json')\n",
    "output_json_path = os.path.join(project_root, 'Data', 'Historical Reddit', 'NER', 'Labeled', 'ner_labeled_reddit_dataset.json')\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(os.path.dirname(output_json_path), exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define allowed entity labels for Reddit context\n",
    "ALLOWED_LABELS = {\n",
    "    \"ORG\": \"Organizations, companies, institutions\",\n",
    "    \"PER\": \"People\",\n",
    "    \"STOCK\": \"Individual company stock symbols and tickers (e.g., AAPL, MSFT, GOOGL)\",\n",
    "    \"INDEX\": \"Market indices and benchmarks (e.g., S&P 500, Russell 2000, Dow Jones, NASDAQ Composite)\",\n",
    "    \"CRYPTO\": \"Cryptocurrency names and symbols\",\n",
    "    \"MONEY\": \"Actual monetary values (e.g., $100, â‚¬50, 2.5 million)\",\n",
    "    \"METRIC\": \"Quantitative measurements (percentages, numbers, statistics, e.g., 50%, 1000 units, 5x growth)\",\n",
    "    \"DATE\": \"Dates and time references\",\n",
    "    \"PRODUCT\": \"Specific financial instruments and services (e.g., 401k, bonds, options, ETFs)\",\n",
    "    \"EVENT\": \"Specific market events and economic conditions (e.g., bull run, recession, market crash)\",\n",
    "    \"CONCEPT\": \"General financial concepts and terms (e.g., diversification, value investing)\",\n",
    "    \"GPE\": \"Countries, cities, states, or administrative regions\",\n",
    "    \"LOC\": \"Physical locations or places\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load or initialize output JSON\n",
    "if os.path.exists(output_json_path):\n",
    "    with open(output_json_path, 'r', encoding='utf-8') as f:\n",
    "        processed_data = json.load(f)\n",
    "    processed_ids = set(item[\"id\"] for item in processed_data)\n",
    "    print(f\"Found {len(processed_ids)} previously processed posts\")\n",
    "else:\n",
    "    processed_data = []\n",
    "    processed_ids = set()\n",
    "    print(\"Starting fresh processing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load input JSON file\n",
    "with open(input_json_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "print(f\"Loaded {len(data)} posts to process\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_entities(entities):\n",
    "    \"\"\"\n",
    "    Validate that all entities use allowed labels\n",
    "    \"\"\"\n",
    "    invalid_labels = set()\n",
    "    for ent in entities:\n",
    "        # Check if ent is a dictionary and has a 'label' key\n",
    "        if isinstance(ent, dict) and \"label\" in ent:\n",
    "            if ent[\"label\"] not in ALLOWED_LABELS:\n",
    "                invalid_labels.add(ent[\"label\"])\n",
    "        else:\n",
    "            # Handle cases where an item in 'entities' is not a dictionary or lacks 'label'\n",
    "            print(f\"Warning: Invalid entity format found: {ent}\")\n",
    "            # Depending on requirements, you might want to raise an error or skip validation for this entity\n",
    "            # For now, let's treat it as an invalid label for simplicity\n",
    "            invalid_labels.add(str(type(ent))) # Add type or placeholder\n",
    "\n",
    "    if invalid_labels:\n",
    "        raise ValueError(f\"Invalid labels found: {invalid_labels}. Allowed labels are: {list(ALLOWED_LABELS.keys())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_processed = 0\n",
    "total_errors = 0\n",
    "posts_to_process = [item for item in data if item.get(\"id\") not in processed_ids]\n",
    "total_remaining = len(posts_to_process)\n",
    "print(f\"Posts remaining to process: {total_remaining}\")\n",
    "\n",
    "for item in posts_to_process:\n",
    "    post_id = item.get(\"id\")\n",
    "    # Redundant check, kept for safety\n",
    "    # if post_id in processed_ids:\n",
    "    #     continue\n",
    "\n",
    "    # Use 'processed_text_finbert' as per the original script\n",
    "    text = item.get(\"processed_text_finbert\", \"\")\n",
    "    if not text: # Skip if text is empty\n",
    "        print(f\"Skipping {post_id}: Empty text field ('processed_text_finbert').\")\n",
    "        continue\n",
    "\n",
    "    prompt = (\n",
    "        \"Label entities in the Reddit post using ONLY these labels:\\n\"\n",
    "        f\"{json.dumps(ALLOWED_LABELS, indent=2)}\\n\\n\"\n",
    "        \"Rules:\\n\"\n",
    "        \"1. Use only the labels above\\n\"\n",
    "        \"2. Include repeated entities\\n\"\n",
    "        \"3. Output as JSON array with 'text' and 'label' fields\\n\"\n",
    "        \"4. Pay attention to Reddit-specific terminology (e.g. stonks, tendies, diamond hands - do not label these unless they refer to actual stocks/concepts)\\n\"\n",
    "        \"5. Do not label general sentiment expressions (e.g., 'to the moon', 'HODL') or emojis as entities\\n\"\n",
    "        \"6. For market indices (like S&P 500, Dow Jones), use INDEX label, not STOCK or ORG\\n\\n\"\n",
    "        \"Example:\\n\"\n",
    "        '[\\n'\n",
    "        '  {\"text\": \"AAPL\", \"label\": \"STOCK\"},\\n'\n",
    "        '  {\"text\": \"S&P 500\", \"label\": \"INDEX\"},\\n'\n",
    "        '  {\"text\": \"the Fed\", \"label\": \"ORG\"},\\n'\n",
    "        '  {\"text\": \"Wall Street\", \"label\": \"LOC\"},\\n'\n",
    "        '  {\"text\": \"24%\", \"label\": \"METRIC\"}\\n'\n",
    "        ']\\n\\n'\n",
    "        f\"Text:\\n{text}\\n\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a NER labeling assistant for Reddit financial posts. Respond with a JSON array of objects containing 'text' and 'label' fields. Use only the specified labels. Pay attention to informal expressions and Reddit-specific terminology.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.1 # Low temperature for more deterministic output\n",
    "        )\n",
    "\n",
    "        # Clean the response and ensure it's valid JSON\n",
    "        response_text = response.choices[0].message.content.strip()\n",
    "        # Remove any markdown code block markers if present\n",
    "        response_text = response_text.replace('```json', '').replace('```', '').strip()\n",
    "\n",
    "        try:\n",
    "            # Handle potential empty or non-JSON responses\n",
    "            if not response_text or not response_text.startswith('['):\n",
    "                    print(f\"Warning for {post_id}: Received non-JSON or empty response: '{response_text}'. Treating as no entities found.\")\n",
    "                    entities = [] # Assume no entities if response is invalid\n",
    "            else:\n",
    "                entities = json.loads(response_text)\n",
    "                # Validate that all labels are allowed\n",
    "                validate_entities(entities)\n",
    "        except (json.JSONDecodeError, ValueError) as e:\n",
    "            print(f\"Error parsing JSON or validating labels for {post_id}: {e}\")\n",
    "            print(f\"Response text received: {response_text}\")\n",
    "            total_errors += 1\n",
    "            continue # Skip saving this item\n",
    "\n",
    "        # Add to processed data\n",
    "        processed_data.append({\n",
    "            \"id\": post_id,\n",
    "            \"text\": text, # Store the text used for labeling\n",
    "            \"entities\": entities\n",
    "        })\n",
    "\n",
    "        # Save after each successful processing\n",
    "        with open(output_json_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(processed_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "        processed_ids.add(post_id) # Add here only after successful save\n",
    "        total_processed += 1\n",
    "        print(f\"Processed {post_id} ({total_processed}/{total_remaining})\")\n",
    "\n",
    "        # Add a small delay to help avoid rate limits\n",
    "        time.sleep(1)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"General error processing {post_id}: {e}\")\n",
    "        total_errors += 1\n",
    "        # Optionally add a longer delay or retry logic here\n",
    "        time.sleep(5) # Longer delay after general error\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nProcessing complete!\")\n",
    "print(f\"Total posts successfully processed in this run: {total_processed}\")\n",
    "print(f\"Total errors encountered in this run: {total_errors}\")\n",
    "if total_processed + total_errors > 0:\n",
    "    success_rate = (total_processed / (total_processed + total_errors)) * 100\n",
    "    print(f\"Success rate for this run: {success_rate:.2f}%\")\n",
    "else:\n",
    "    print(\"No new posts processed in this run.\")\n",
    "print(f\"Total labeled posts in output file: {len(processed_data)}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
