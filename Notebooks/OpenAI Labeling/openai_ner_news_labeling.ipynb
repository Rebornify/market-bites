{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from openai import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide your OpenAI API key\n",
    "# WARNING: Storing API keys directly in code is not recommended for production.\n",
    "# Consider using environment variables or a secure key management system.\n",
    "api_key = \"\"\n",
    "client = OpenAI(api_key=api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Paths for Data and Output\n",
    "project_root = '/content/drive/MyDrive/IS450 Project'\n",
    "input_json_path = os.path.join(project_root, 'Data', 'Historical News', 'NER_Data', 'Unlabeled', '5000_news_for_NER.json')\n",
    "output_json_path = os.path.join(project_root, 'Data', 'Historical News', 'NER_Data', 'Labeled', 'ner_labeled_news_dataset.json')\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(os.path.dirname(output_json_path), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define allowed entity labels\n",
    "ALLOWED_LABELS = {\n",
    "    \"ORG\": \"Organizations, companies, institutions\",\n",
    "    \"PER\": \"People\",\n",
    "    \"STOCK\": \"Individual company stock symbols and tickers (e.g., AAPL, MSFT, GOOGL)\",\n",
    "    \"INDEX\": \"Market indices and benchmarks (e.g., S&P 500, Russell 2000, Dow Jones, NASDAQ Composite)\",\n",
    "    \"CRYPTO\": \"Cryptocurrency names and symbols\",\n",
    "    \"MONEY\": \"Actual monetary values (e.g., $100, â‚¬50, 2.5 million)\",\n",
    "    \"METRIC\": \"Quantitative measurements (percentages, numbers, statistics, e.g., 50%, 1000 units, 5x growth)\",\n",
    "    \"DATE\": \"Dates and time periods\",\n",
    "    \"PRODUCT\": \"Products, services, or technologies\",\n",
    "    \"EVENT\": \"Events, meetings, or occurrences\",\n",
    "    \"LOC\": \"Locations (places, buildings, landmarks)\",\n",
    "    \"GPE\": \"Geopolitical entities (countries, cities, regions)\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load or initialize output JSON\n",
    "if os.path.exists(output_json_path):\n",
    "    with open(output_json_path, 'r', encoding='utf-8') as f:\n",
    "        processed_data = json.load(f)\n",
    "    processed_ids = set(item[\"id\"] for item in processed_data)\n",
    "    print(f\"Found {len(processed_ids)} previously processed articles\")\n",
    "else:\n",
    "    processed_data = []\n",
    "    processed_ids = set()\n",
    "    print(\"Starting fresh processing\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load input JSON file\n",
    "with open(input_json_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "print(f\"Loaded {len(data)} articles to process\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_entities(entities):\n",
    "    \"\"\"\n",
    "    Validate that all entities use allowed labels\n",
    "    \"\"\"\n",
    "    invalid_labels = set()\n",
    "    for ent in entities:\n",
    "        if ent[\"label\"] not in ALLOWED_LABELS:\n",
    "            invalid_labels.add(ent[\"label\"])\n",
    "\n",
    "    if invalid_labels:\n",
    "        raise ValueError(f\"Invalid labels found: {invalid_labels}. Allowed labels are: {list(ALLOWED_LABELS.keys())}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_processed = 0\n",
    "total_errors = 0\n",
    "articles_to_process = [item for item in data if item.get(\"id\") not in processed_ids]\n",
    "total_remaining = len(articles_to_process)\n",
    "print(f\"Articles remaining to process: {total_remaining}\")\n",
    "\n",
    "\n",
    "for item in articles_to_process:\n",
    "    post_id = item.get(\"id\")\n",
    "    # This check is redundant now but kept for safety\n",
    "    # if post_id in processed_ids:\n",
    "    #     continue\n",
    "\n",
    "    text = item.get(\"text\", \"\")\n",
    "    prompt = (\n",
    "        \"Label entities in the text using ONLY these labels:\\n\"\n",
    "        f\"{json.dumps(ALLOWED_LABELS, indent=2)}\\n\\n\"\n",
    "        \"Rules:\\n\"\n",
    "        \"1. Use only the labels above\\n\"\n",
    "        \"2. Output as JSON array with 'text' and 'label' fields\\n\"\n",
    "        \"3. The 'text' field must be the exact substring from the original text\\n\"\n",
    "        \"4. Entities must not overlap. If a shorter entity is part of a longer one, only label the longer entity (e.g., label \\\"S&P 500 Index\\\" as INDEX, not \\\"S&P 500\\\").\\n\\n\"\n",
    "        \"Example:\\n\"\n",
    "        '[\\n'\n",
    "        '  {\"text\": \"Microsoft\", \"label\": \"ORG\"},\\n'\n",
    "        '  {\"text\": \"AAPL\", \"label\": \"STOCK\"},\\n'\n",
    "        '  {\"text\": \"S&P 500 Index\", \"label\": \"INDEX\"},\\n'\n",
    "        '  {\"text\": \"New York\", \"label\": \"GPE\"}\\n'\n",
    "        ']\\n\\n'\n",
    "        f\"Text:\\n{text}\\n\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a NER labeling assistant. Respond with a JSON array of objects containing 'text' and 'label' fields. The 'text' field must be the exact substring. Use only the specified labels.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.1\n",
    "        )\n",
    "\n",
    "        # Clean the response and ensure it's valid JSON\n",
    "        response_text = response.choices[0].message.content.strip()\n",
    "        # Remove any markdown code block markers if present\n",
    "        response_text = response_text.replace('```json', '').replace('```', '').strip()\n",
    "\n",
    "        try:\n",
    "            entities = json.loads(response_text)\n",
    "            # Validate that all labels are allowed\n",
    "            validate_entities(entities)\n",
    "        except (json.JSONDecodeError, ValueError) as e:\n",
    "            print(f\"Error parsing JSON or validating labels for {post_id}: {e}\")\n",
    "            print(f\"Response text received: {response_text}\")\n",
    "            total_errors += 1\n",
    "            continue # Skip saving this item\n",
    "\n",
    "        # Add to processed data\n",
    "        processed_data.append({\n",
    "            \"id\": post_id,\n",
    "            \"text\": text,\n",
    "            \"entities\": entities\n",
    "        })\n",
    "\n",
    "        # Save after each successful processing\n",
    "        with open(output_json_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(processed_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "        processed_ids.add(post_id) # Add here only after successful save\n",
    "        total_processed += 1\n",
    "        print(f\"Processed {post_id} ({total_processed}/{total_remaining})\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"General error processing {post_id}: {e}\")\n",
    "        total_errors += 1\n",
    "        # Optionally add a delay or retry logic here\n",
    "        time.sleep(1) # Simple delay\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nProcessing complete!\")\n",
    "print(f\"Total articles successfully processed in this run: {total_processed}\")\n",
    "print(f\"Total errors encountered in this run: {total_errors}\")\n",
    "if total_processed + total_errors > 0:\n",
    "    success_rate = (total_processed / (total_processed + total_errors)) * 100\n",
    "    print(f\"Success rate for this run: {success_rate:.2f}%\")\n",
    "else:\n",
    "    print(\"No new articles processed in this run.\")\n",
    "print(f\"Total labeled articles in output file: {len(processed_data)}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
